{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab0f11-efd3-450b-874d-c51a768da1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pysindy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0df213d-81f9-47d1-8a2e-083193081f74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:25.499717Z",
     "start_time": "2021-10-26T11:26:22.845419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cpu\n"
     ]
    }
   ],
   "source": [
    "#commom imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from torch.autograd import grad\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#deepmod imports, folder is local\n",
    "sys.path.insert(0, './DeePyMoD/src/')\n",
    "# DeepMoD functions\n",
    "from deepymod import DeepMoD\n",
    "from deepymod.model.func_approx import NN\n",
    "from deepymod.data import Dataset, get_train_test_loader\n",
    "from deepymod.model.library import Library1D\n",
    "from deepymod import Library\n",
    "from deepymod.model.constraint import LeastSquares\n",
    "from deepymod.model.sparse_estimators import Threshold,PDEFIND\n",
    "from deepymod.training import train\n",
    "from deepymod.training.sparsity_scheduler import TrainTestPeriodic\n",
    "from deepymod.model.func_approx import Siren\n",
    "from deepymod.utils.logger import Logger\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "#device will be cpu for now, changes are required to make it cuda compatible\n",
    "device = \"cpu\"\n",
    "print(\"Device is:\",device)\n",
    "\n",
    "#auxiliar functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c3c3b4a-0b35-4cd3-941c-dbdbd1e79e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:25.533184Z",
     "start_time": "2021-10-26T11:26:25.504028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "class SinCosLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        p_list: List[float]\n",
    "    ) -> None:\n",
    "        \"\"\"Sin/Cos activation function layer with different period.\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p_list = p_list\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the layer.\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape (n_samples, n_inputs).\n",
    "        Returns:\n",
    "            torch.Tensor: Prediction of shape (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        n_in = input.shape[1]\n",
    "        n_p = len(self.p_list)\n",
    "        \n",
    "        sincos_list = []\n",
    "        for i in range(n_p):\n",
    "            omega = 2.0*np.pi/self.p_list[i]\n",
    "            \n",
    "            sincos_list.append(torch.sin(omega*input[:, 0:1]))\n",
    "            sincos_list.append(torch.cos(omega*input[:, 0:1]))\n",
    "            \n",
    "        output = torch.cat([input] + sincos_list, dim=1)\n",
    "        \n",
    "        return output       \n",
    "        \n",
    "\n",
    "class SCNN(torch.nn.Module):\n",
    "    def __init__(self, n_in: int, n_hidden: List[int], n_out: int, p_list: List[float]) -> None:\n",
    "        \"\"\"Constructs a feed-forward neural network with tanh activation.\n",
    "        Args:\n",
    "            n_in (int): Number of input features.\n",
    "            n_hidden (List[int]): Number of neurons in each layer.\n",
    "            n_out (int): Number of output features.\n",
    "            p_list (List[float]): list of sin/cos period\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p_list = p_list\n",
    "        self.network = self.build_network(n_in, n_hidden, n_out, p_list)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Forward pass through the network. Returns prediction and the differentiable input\n",
    "        so we can construct the library.\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of size (n_samples, n_inputs).\n",
    "        Returns:\n",
    "            (torch.Tensor, torch.Tensor): prediction of size (n_samples, n_outputs) and coordinates of size (n_samples, n_inputs).\n",
    "        \"\"\"\n",
    "        coordinates = input.clone().detach().requires_grad_(True)\n",
    "        return self.network(coordinates), coordinates\n",
    "\n",
    "    def build_network(self, n_in: int, n_hidden: List[int], n_out: int, p_list: [float]) -> torch.nn.Sequential:\n",
    "        \"\"\"Constructs a feed-forward neural network.\n",
    "        Args:\n",
    "            n_in (int): Number of input features.\n",
    "            n_hidden (list[int]): Number of neurons in each layer.\n",
    "            n_out (int): Number of output features.\n",
    "            p_list (List[float]): list of sin/cos period\n",
    "        Returns:\n",
    "            torch.Sequential: Pytorch module\n",
    "        \"\"\"\n",
    "\n",
    "        network = [SinCosLayer(p_list)]\n",
    "        \n",
    "        n_sc_out = n_in + len(p_list) * 2\n",
    "        \n",
    "        architecture = [n_sc_out] + n_hidden + [n_out]\n",
    "        for layer_i, layer_j in zip(architecture, architecture[1:]):\n",
    "            network.append(torch.nn.Linear(layer_i, layer_j))\n",
    "            network.append(torch.nn.Tanh())\n",
    "        network.pop()  # get rid of last activation function\n",
    "        return torch.nn.Sequential(*network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933a868-d805-4d97-ab56-42a41a902700",
   "metadata": {},
   "source": [
    "# 1D Implementation - Tanh neural nets, SIREN, Custom Sinusoidal, Custom 1D library and Error Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21eea030-b5e1-4338-816c-07709df65f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:28.786261Z",
     "start_time": "2021-10-26T11:26:25.536369Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time1</th>\n",
       "      <th>Time2</th>\n",
       "      <th>Para</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Val</th>\n",
       "      <th>Houridx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>PRES</td>\n",
       "      <td>surface</td>\n",
       "      <td>-20</td>\n",
       "      <td>23</td>\n",
       "      <td>102132.0</td>\n",
       "      <td>333095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>PRES</td>\n",
       "      <td>surface</td>\n",
       "      <td>-19</td>\n",
       "      <td>23</td>\n",
       "      <td>102022.0</td>\n",
       "      <td>333095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>PRES</td>\n",
       "      <td>surface</td>\n",
       "      <td>-18</td>\n",
       "      <td>23</td>\n",
       "      <td>102090.0</td>\n",
       "      <td>333095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>PRES</td>\n",
       "      <td>surface</td>\n",
       "      <td>-17</td>\n",
       "      <td>23</td>\n",
       "      <td>102077.0</td>\n",
       "      <td>333095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>2008-01-01 00:00:00</td>\n",
       "      <td>PRES</td>\n",
       "      <td>surface</td>\n",
       "      <td>-16</td>\n",
       "      <td>23</td>\n",
       "      <td>101260.0</td>\n",
       "      <td>333095.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time1                Time2  Para      Alt  Lon  Lat  \\\n",
       "0  2008-01-01 00:00:00  2008-01-01 00:00:00  PRES  surface  -20   23   \n",
       "1  2008-01-01 00:00:00  2008-01-01 00:00:00  PRES  surface  -19   23   \n",
       "2  2008-01-01 00:00:00  2008-01-01 00:00:00  PRES  surface  -18   23   \n",
       "3  2008-01-01 00:00:00  2008-01-01 00:00:00  PRES  surface  -17   23   \n",
       "4  2008-01-01 00:00:00  2008-01-01 00:00:00  PRES  surface  -16   23   \n",
       "\n",
       "        Val   Houridx  \n",
       "0  102132.0  333095.0  \n",
       "1  102022.0  333095.0  \n",
       "2  102090.0  333095.0  \n",
       "3  102077.0  333095.0  \n",
       "4  101260.0  333095.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./dataframe.pk.zip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654772b7-7f34-4f9d-ac8a-f9948c8897ed",
   "metadata": {},
   "source": [
    "For future work, what can be done is investigating correlation between all these variables and temperature and then use the ones that are highly correlated as inputs to the model to estimate temperature in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb06a53-c2c0-43ed-87be-024e8a1d2b65",
   "metadata": {},
   "source": [
    "## Data preprocessing - Only temperature in Celsius, only on surface, only on (28,-15); Time in days since 01/01/2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f64cbeb-e696-4531-a4be-151daa6e271b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:30.288133Z",
     "start_time": "2021-10-26T11:26:28.792174Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4832\n"
     ]
    }
   ],
   "source": [
    "#getting only temperature at surface level and at point(28,-15), that's why it's 1D\n",
    "case1_df = df[(df.Para == \"TMP\") & (df.Alt == \"surface\") & (df.Lat == 28) & (df.Lon == -15)]\n",
    "\n",
    "#converting temperature to Celsiu and then normalizing\n",
    "temporary_df = case1_df.copy()\n",
    "temporary_df.Val -= 273.15\n",
    "#scaled to [0,1]\n",
    "#temporary_df[\"Val\"]  = (temporary_df[\"Val\"] - temporary_df[\"Val\"].min())/(temporary_df[\"Val\"].max()-temporary_df[\"Val\"].min())\n",
    "\n",
    "#scaled to [-1,1]\n",
    "temporary_df[\"Val\"]         = 1 + (((temporary_df[\"Val\"]-temporary_df[\"Val\"].min())*(-1-1))/(temporary_df[\"Val\"].max()-temporary_df[\"Val\"].min()))\n",
    "\n",
    "#converting date to days, starting at 0 at the 1st inicial day\n",
    "inicial_time = temporary_df[\"Houridx\"].iloc[0]\n",
    "temporary_df.Houridx -= inicial_time\n",
    "\n",
    "final_df = temporary_df.copy()\n",
    "final_df[\"Houridx\"] = final_df[\"Houridx\"]/24.0\n",
    "\n",
    "temperature_array = final_df[\"Val\"].to_numpy()\n",
    "time_array        = final_df[\"Houridx\"].to_numpy()\n",
    "print(len(time_array))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e68c3f5b-d16a-4e1f-bb13-19c121b7a62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f96892dd1f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7f96481e83a0> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Temperature\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Temperature($^\\circ$C )\")\n",
    "plt.plot(final_df[\"Houridx\"]/365+2008,final_df[\"Val\"],linewidth=2,label=\"Temperature\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88000fe-afb6-49a9-a250-55b6d68a411d",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Fourier Transform to get the main frequencies present on the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be895d2b-da1e-40a3-957a-f143e151b5de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:30.589430Z",
     "start_time": "2021-10-26T11:26:30.292229Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The 10 frequencies with the biggest coefs are:\n",
      "[0.         0.07553808 0.15107616 0.67984272 0.75538079 0.83091887\n",
      " 0.98199503 1.05753311 1.96399007 2.03952815]\n"
     ]
    }
   ],
   "source": [
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "total_time_points = time_array.shape[0]\n",
    "yf = rfft(temperature_array)\n",
    "xf = rfftfreq(total_time_points)\n",
    "\n",
    "#table = hv.Table((xf[:50].reshape(1,-1)*365,np.abs(yf[:50].reshape(1,-1))), 'x', 'y')\n",
    "\n",
    "#curve = hv.Curve(table).opts(frame_width=1000,xlabel=\"Time in years\")\n",
    "\n",
    "#getting the frequencies with higher coeficients\n",
    "\n",
    "sorted_yf = sorted(np.abs(yf),reverse=True)\n",
    "\n",
    "print()\n",
    "print()\n",
    "frequencies = []\n",
    "\n",
    "for i,coef in enumerate(np.abs(yf)):\n",
    "    if coef in sorted_yf[:10]:\n",
    "        frequencies.append((xf[i]))\n",
    "\n",
    "print(\"The 10 frequencies with the biggest coefs are:\")    \n",
    "print(np.array(frequencies)*365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a072db0-2a19-4b14-8a23-e9bb8d6c7b29",
   "metadata": {},
   "source": [
    "So we see in terms of months that we some sort of monthly peridiocity.\n",
    "\n",
    "This information will be useful when building the Libary of functions that will than fit the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd2534-8fb9-4cf6-b951-02b077426ed2",
   "metadata": {},
   "source": [
    "## Dataset function creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79257690-2436-4c68-b44b-15bb69a2b84c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:34.130856Z",
     "start_time": "2021-10-26T11:26:34.084277Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4832, 1])\n"
     ]
    }
   ],
   "source": [
    "#creating the dataset loader\n",
    "\n",
    "t_train = torch.tensor(time_array,dtype=torch.float32).view(-1,1)\n",
    "print(t_train.shape)\n",
    "#test to see if inputing the coords helps solving the error\n",
    "#we have only one point in space so I will just fill x_train with ones, is not important\n",
    "x_train = torch.ones_like(t_train)\n",
    "\n",
    "Y_train = torch.tensor(temperature_array,dtype=torch.float32).view(-1,1)\n",
    "X_train = torch.cat((t_train,x_train),dim=1)\n",
    "\n",
    "n_train = int(X_train.shape[0]*1)\n",
    "auxiliar = X_train[:n_train,:], Y_train[:n_train,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f57b1a0-43a8-4638-8a1a-29ef510c2fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:38.758918Z",
     "start_time": "2021-10-26T11:26:38.705215Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(auxiliar,device=device)\n",
    "\n",
    "train_dataloader, test_dataloader = get_train_test_loader(\n",
    "    dataset, train_test_split=0.8\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13dd03-8212-4d56-b237-df57395fc3b5",
   "metadata": {},
   "source": [
    "## Plotting Auxiliary function --> Later to be put on a different script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26ec830c-37ef-46c6-a4d9-a7a3a880131f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T11:26:44.766375Z",
     "start_time": "2021-10-26T11:26:44.708978Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotting_predictions(number_of_years:int,filename,test_fraction:int=0.8,time_array=time_array,temperature_array=temperature_array,show_error=False):\n",
    "    x_array     = np.arange(0,365*number_of_years,1)\n",
    "    pred_array  = np.zeros(x_array.shape)\n",
    "    \n",
    "    #error should only be used in test set\n",
    "    test_index = int(test_fraction*len(time_array))\n",
    "    error_array = np.zeros(time_array[test_index:].shape)\n",
    "    rmse = 0\n",
    "    mae  = 0 \n",
    "    for i,t in enumerate(x_array):\n",
    "        in_data            = [[t,1]]\n",
    "        prediction         = model.func_approx(torch.Tensor(in_data))[0].item()\n",
    "        pred_array[i]      = prediction\n",
    "        if (i >= test_index) and i < (len(time_array)-1) :\n",
    "            diff = (temperature_array[i] - prediction)\n",
    "            error_array[i-test_index] = diff/temperature_array[i]*100\n",
    "        \n",
    "            rmse += diff**2\n",
    "            mae  += np.abs(diff)\n",
    "\n",
    "    #correct expression is the 1st one but I only noticed I had a mistake after training most of my models so I will leave it like\n",
    "    # this fow now and then calculate new errors later\n",
    "    \n",
    "    #rmse = np.sqrt((rmse)/len(error_array))\n",
    "    rmse = np.sqrt(rmse)/len(error_array)\n",
    "    mae  = mae/len(error_array)\n",
    "    np.savetxt(filename,(x_array,pred_array),delimiter=\",\")\n",
    "    \n",
    "        \n",
    "       \n",
    "    #prediction plot\n",
    "    fig = plt.figure(figsize=(20,9)) \n",
    "    plt.scatter(x_array/365+2008,pred_array,c=\"r\",label=\"Model\")\n",
    "    plt.plot(time_array[:int(0.8*len(time_array))]/365.0+2008, temperature_array[:int(0.8*len(time_array))], '*b', label='Train Data')\n",
    "    plt.plot(time_array[int(0.8*len(time_array)):]/365.0+2008,temperature_array[int(0.8*len(time_array)):],\"*g\",label =\"Test Data\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"{filename}\")\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Normalized Temperature')\n",
    "    #plt.savefig(\"plot.png\")\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    if show_error:\n",
    "        #error plot\n",
    "        plt.figure(figsize=(20,9))\n",
    "        plt.scatter(time_array[test_index:]/365+2008,error_array,c=\"navy\",label=\"Relative error\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Relative Error(%)')\n",
    "        plt.show()\n",
    "\n",
    "        #zoomed error plot, ignore outliers\n",
    "        plt.figure(figsize=(20,9))\n",
    "        plt.scatter(time_array[test_index:]/365+2008,error_array,c=\"navy\",label=\"Relative error\")\n",
    "        plt.ylim(-10,100)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Relative Error(%)')\n",
    "        plt.show()\n",
    "    \n",
    "    #error printing\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE:\",mae)\n",
    "    \n",
    "    return rmse,mae,x_array, pred_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7658ea2-9d87-4def-a9b4-0a32f1eab87e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation using just DeepMod source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad5833ff-4236-4828-aca2-61ee0c77f809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.739419Z",
     "start_time": "2021-10-26T09:28:41.739406Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = Siren(2, [30, 30,30,30], 1,3,3)\n",
    "library = Library1D(poly_order=2, diff_order=3)\n",
    "estimator = Threshold(0.1) \n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=50, delta=1e-5)\n",
    "constraint = LeastSquares()\n",
    "model = DeepMoD(network, library, estimator, constraint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e45148de-3938-42e5-8c82-8003ed74dcf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.741421Z",
     "start_time": "2021-10-26T09:28:41.741403Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b465a7-d41f-49ec-a41d-1540f7c683e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.743954Z",
     "start_time": "2021-10-26T09:28:41.743942Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<deepymod.utils.logger.Logger object at 0x7f94d124ffd0>\n",
      "IM here\n",
      "     0  MSE: 3.12e-01   MSE_TEST: 2.99e-01   Reg: 1.10e-01  L1: 1.98e-01 \n",
      "   100  MSE: 1.72e-01   MSE_TEST: 1.71e-01   Reg: 2.71e-02  L1: 1.26e+00 \n",
      "   200  MSE: 1.22e-01   MSE_TEST: 1.21e-01   Reg: 6.05e-02  L1: 1.21e+00 \n",
      "   300  MSE: 7.45e-02   MSE_TEST: 7.47e-02   Reg: 6.62e-02  L1: 7.83e-01 \n",
      "   400  MSE: 5.28e-02   MSE_TEST: 5.19e-02   Reg: 8.19e-02  L1: 7.77e-01 \n",
      "   500  MSE: 3.80e-02   MSE_TEST: 3.79e-02   Reg: 8.08e-02  L1: 8.99e-01 \n",
      "   600  MSE: 3.02e-02   MSE_TEST: 3.00e-02   Reg: 8.69e-02  L1: 6.74e-01 \n",
      "   700  MSE: 2.42e-02   MSE_TEST: 2.41e-02   Reg: 9.78e-02  L1: 6.76e-01 \n",
      "   800  MSE: 2.00e-02   MSE_TEST: 2.00e-02   Reg: 1.11e-01  L1: 5.41e-01 \n",
      "   900  MSE: 1.70e-02   MSE_TEST: 1.72e-02   Reg: 1.27e-01  L1: 4.93e-01 \n",
      "  1000  MSE: 1.44e-02   MSE_TEST: 1.47e-02   Reg: 1.41e-01  L1: 4.99e-01 \n",
      "  1100  MSE: 1.29e-02   MSE_TEST: 1.28e-02   Reg: 1.56e-01  L1: 5.31e-01 \n",
      "  1200  MSE: 1.14e-02   MSE_TEST: 1.13e-02   Reg: 1.68e-01  L1: 5.23e-01 \n",
      "  1300  MSE: 9.98e-03   MSE_TEST: 9.93e-03   Reg: 1.80e-01  L1: 5.20e-01 \n",
      "  1400  MSE: 8.97e-03   MSE_TEST: 8.89e-03   Reg: 1.93e-01  L1: 5.61e-01 \n",
      "  1500  MSE: 8.27e-03   MSE_TEST: 8.13e-03   Reg: 2.06e-01  L1: 5.78e-01 \n",
      "  1600  MSE: 7.93e-03   MSE_TEST: 7.92e-03   Reg: 2.17e-01  L1: 6.32e-01 \n",
      "  1700  MSE: 6.89e-03   MSE_TEST: 7.01e-03   Reg: 2.29e-01  L1: 6.36e-01 \n",
      "  1800  MSE: 6.18e-03   MSE_TEST: 6.17e-03   Reg: 2.40e-01  L1: 6.34e-01 \n",
      "  1900  MSE: 6.02e-03   MSE_TEST: 5.90e-03   Reg: 2.49e-01  L1: 6.48e-01 \n",
      "  2000  MSE: 7.52e-03   MSE_TEST: 7.67e-03   Reg: 2.57e-01  L1: 6.28e-01 \n",
      "  2100  MSE: 7.52e-03   MSE_TEST: 7.67e-03   Reg: 2.59e-01  L1: 3.01e-01 \n",
      "  2200  MSE: 5.28e-03   MSE_TEST: 5.42e-03   Reg: 2.66e-01  L1: 3.01e-01 \n",
      "  2300  MSE: 5.06e-03   MSE_TEST: 4.89e-03   Reg: 2.73e-01  L1: 3.04e-01 \n",
      "  2400  MSE: 4.64e-03   MSE_TEST: 4.69e-03   Reg: 2.81e-01  L1: 3.06e-01 \n",
      "  2500  MSE: 4.40e-03   MSE_TEST: 4.37e-03   Reg: 2.92e-01  L1: 3.11e-01 \n",
      "  2600  MSE: 4.29e-03   MSE_TEST: 4.29e-03   Reg: 2.98e-01  L1: 3.14e-01 \n",
      "  2700  MSE: 3.86e-03   MSE_TEST: 3.84e-03   Reg: 3.02e-01  L1: 3.15e-01 \n",
      "  2800  MSE: 3.80e-03   MSE_TEST: 3.87e-03   Reg: 3.08e-01  L1: 3.17e-01 \n",
      "  2900  MSE: 3.69e-03   MSE_TEST: 3.60e-03   Reg: 3.13e-01  L1: 3.18e-01 \n",
      "  3000  MSE: 4.28e-03   MSE_TEST: 4.12e-03   Reg: 3.17e-01  L1: 3.21e-01 \n",
      "  3100  MSE: 3.49e-03   MSE_TEST: 3.58e-03   Reg: 3.20e-01  L1: 3.20e-01 \n",
      "  3200  MSE: 3.32e-03   MSE_TEST: 3.28e-03   Reg: 3.27e-01  L1: 3.19e-01 \n",
      "  3300  MSE: 3.06e-03   MSE_TEST: 3.06e-03   Reg: 3.30e-01  L1: 3.19e-01 \n",
      "  3400  MSE: 2.96e-03   MSE_TEST: 3.07e-03   Reg: 3.33e-01  L1: 3.20e-01 \n",
      "  3500  MSE: 2.96e-03   MSE_TEST: 2.92e-03   Reg: 3.38e-01  L1: 3.19e-01 \n",
      "  3600  MSE: 2.86e-03   MSE_TEST: 2.82e-03   Reg: 3.46e-01  L1: 3.18e-01 \n",
      "  3700  MSE: 2.92e-03   MSE_TEST: 2.80e-03   Reg: 3.46e-01  L1: 3.17e-01 \n",
      "  3800  MSE: 3.88e-03   MSE_TEST: 4.05e-03   Reg: 3.52e-01  L1: 3.19e-01 \n",
      "  3900  MSE: 2.66e-03   MSE_TEST: 2.64e-03   Reg: 3.53e-01  L1: 3.16e-01 \n",
      "  4000  MSE: 2.61e-03   MSE_TEST: 2.74e-03   Reg: 3.57e-01  L1: 3.16e-01 \n",
      "  4100  MSE: 2.66e-03   MSE_TEST: 2.69e-03   Reg: 3.59e-01  L1: 3.16e-01 \n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    train_dataloader,\n",
    "    optimizer,\n",
    "    sparsity_scheduler,\n",
    "    exp_ID=None,\n",
    "    log_dir = None,\n",
    "    write_iterations=100,\n",
    "    max_iterations=5000,\n",
    "    delta=1e-4,\n",
    "    patience=50,\n",
    "    reg_coef = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407fd3d6-ce86-4019-939b-7d47b6201c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.746253Z",
     "start_time": "2021-10-26T09:28:41.746240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.sparsity_masks)\n",
    "print()\n",
    "\n",
    "#just printing as rows to facilite visualization\n",
    "coefs = np.reshape(model.estimator_coeffs(),(1,-1))\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ccc56-1848-4d50-a0c5-56be84417edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.748839Z",
     "start_time": "2021-10-26T09:28:41.748822Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotting_predictions(number_of_years=20,filename=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76c796-0383-4d85-964f-a7bb24f676c5",
   "metadata": {},
   "source": [
    "### Implementation a custom Library with sinusoidal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4c98b-9616-4888-8e16-1fdb52c6f30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.750949Z",
     "start_time": "2021-10-26T09:28:41.750936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "class CustomLibrary(Library):\n",
    "\n",
    "    def __init__(self, poly_order: int, diff_order: int, frequencies_list: list[float],full_library=False):\n",
    "        super().__init__()\n",
    "        self.poly_order     = poly_order\n",
    "        self.diff_order     = diff_order\n",
    "        self.frequencies    = frequencies_list\n",
    "        self.full_library = full_library\n",
    "\n",
    "    def library(self, input: tuple[torch.Tensor, torch.Tensor]) -> tuple[list, list]:\n",
    "        prediction, data = input\n",
    "        lib = Library1D(poly_order=self.poly_order, diff_order=self.diff_order)\n",
    "\n",
    "        time_deriv_list, default_theta = lib.library(input=input)\n",
    "        \n",
    "        #default_theta_tensor = torch.stack(default_theta)\n",
    "        #print(time_deriv_list.dtype)\n",
    "\n",
    "        time_array = data[:, 0:1]\n",
    "        c = torch.ones(time_array.shape[0],1)\n",
    "        for i,frequency in enumerate(self.frequencies):\n",
    "            omega       = 2*np.pi*frequency # when \"period\" is actually the frequency\n",
    "            #sines     = torch.sin(time_array*omega).reshape(-1,1)\n",
    "            #cossines   = torch.cos(time_array*omega).reshape(-1,1)\n",
    "            d_sines     = omega*torch.sin(time_array*omega).reshape(-1,1)\n",
    "            d_cossines  = -omega*torch.cos(time_array*omega).reshape(-1,1)\n",
    "            #sines2      = -omega*omega*torch.sin(time_array*omega).reshape(-1,1)\n",
    "            #cossines2   = -omega*omega*torch.cos(time_array*omega).reshape(-1,1)\n",
    "            #print(sines)\n",
    "            b        = torch.hstack((c,d_cossines,d_sines))\n",
    "            c        = torch.clone(b)\n",
    "            \n",
    "        if self.full_library:\n",
    "            sinu_theta = c[:,1:]#default theta already has a 1 column\n",
    "            theta = torch.cat([default_theta + sinu_theta],dim=1)\n",
    "        else:\n",
    "            theta = c\n",
    "        \n",
    "        return time_deriv_list, [theta]\n",
    "    \n",
    "\n",
    "class Library_nonlinear(Library):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        Library ([type]): [description]\n",
    "    \"\"\"\n",
    "    def __init__(self, period_list) -> None:\n",
    "        super().__init__()\n",
    "        self.period_list = period_list\n",
    "        \n",
    "        self.cal_count = 0\n",
    "\n",
    "    #def library(self, input: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[TensorList, TensorList]:\n",
    "    def library(self, input):\n",
    "        prediction, data = input\n",
    "        samples = prediction.shape[0]\n",
    "        \n",
    "        n_order = int((data.shape[1] - 1)/2.0)\n",
    "                \n",
    "        # Construct the theta matrix\n",
    "        C = torch.ones_like(prediction[:,0]).view(samples, -1)\n",
    "        \n",
    "        # ipdb.set_trace()\n",
    "        \n",
    "        time_array = data[:, 0:1]\n",
    "        arg_state_list = []\n",
    "        for i in range(len(self.period_list)):\n",
    "            omega = 2.0*np.pi/self.period_list[i]\n",
    "            arg_state_list.append(torch.sin(time_array*omega)*omega)\n",
    "            arg_state_list.append(torch.cos(time_array*omega)*omega) \n",
    "        \n",
    "        #arg_state_list = []\n",
    "        #for i in range(n_order):\n",
    "        #    arg_state_list.append(data[:, 2*i+2].view(samples, -1))\n",
    "        #    arg_state_list.append(data[:, 2*i+1].view(samples, -1)*-1.0)\n",
    "        \n",
    "        theta = torch.cat([C] + arg_state_list, dim=1)\n",
    "    \n",
    "        # Construct a list of time_derivatives \n",
    "        time_deriv_list = []\n",
    "        for output in torch.arange(prediction.shape[1]):\n",
    "            dy = grad(prediction[:,output], data, grad_outputs=torch.ones_like(prediction[:,output]), create_graph=True, allow_unused=True)[0]\n",
    "            time_deriv = dy[:, 0:1]\n",
    "            time_deriv_list.append(time_deriv)       \n",
    "        \n",
    "        return time_deriv_list, [theta[:, 1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc345adb-0d78-4fe8-83f1-e9f104d20433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.752701Z",
     "start_time": "2021-10-26T09:28:41.752689Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftt_frequencies_list = np.array(frequencies[1:])\n",
    "\n",
    "network            = Siren(2, [30,30,30,30,30], 1,first_omega_0=3,hidden_omega_0=3)\n",
    "library            = CustomLibrary(poly_order=4, diff_order=1,frequencies_list=ftt_frequencies_list)\n",
    "estimator          = PDEFIND()\n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=10, delta=1e-4)\n",
    "constraint         = LeastSquares()\n",
    "model              = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "optimizer          = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c9015-b337-400b-884e-aca246bbe609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.754501Z",
     "start_time": "2021-10-26T09:28:41.754491Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    sparsity_scheduler,\n",
    "    exp_ID=\"Test\",\n",
    "    write_iterations=1000,\n",
    "    max_iterations=5001,\n",
    "    delta=1e-4,\n",
    "    patience=8,\n",
    "    reg_coef = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc2761-c4b3-4dde-90d2-eac46dc5e1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.756281Z",
     "start_time": "2021-10-26T09:28:41.756266Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.sparsity_masks)\n",
    "print()\n",
    "\n",
    "#just printing as rows to facilitate visualization\n",
    "coefs = np.reshape(model.estimator_coeffs(),(1,-1))\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fde404-fe0f-44dc-9a40-f0b7dbb33966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.758424Z",
     "start_time": "2021-10-26T09:28:41.758396Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotting_predictions(number_of_years=20,filename=\"test\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9e42e-3bca-451d-9fc9-96c4fc336414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.760424Z",
     "start_time": "2021-10-26T09:28:41.760411Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_several_runs(nr_runs:int = 10,\n",
    "                          ftt_period_list = np.array(frequencies[1:]),\n",
    "                          filename = \"test\",max_iterations:int = 100000,\n",
    "                          reg_coef:float = 1,k_mse_loss:float = 1,\n",
    "                          learning_rate:float = 1e-3,\n",
    "                          omega:int = 3,\n",
    "                          nr_of_neurons:int = 30,\n",
    "                          nr_layers:int = 7,\n",
    "                          full_library = False):\n",
    "    \n",
    "    \n",
    "    coefs_list     = []\n",
    "    rmse_list      = []\n",
    "    mae_list       = []\n",
    "    \n",
    "    #loop for training the model for each run\n",
    "    for i in range(nr_runs):\n",
    "        network            = Siren(2, nr_layers*[nr_of_neurons],1,first_omega_0=omega,hidden_omega_0=omega)\n",
    "        library            = CustomLibrary(poly_order=3, diff_order=2,frequencies_list=ftt_period_list,full_library=full_library)\n",
    "        estimator          = Threshold(0.01)\n",
    "        sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=10, delta=1e-3)\n",
    "        constraint         = LeastSquares()\n",
    "        model              = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "        optimizer          = torch.optim.AdamW(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=learning_rate)\n",
    "        train(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            test_dataloader,\n",
    "            optimizer,\n",
    "            sparsity_scheduler,\n",
    "            exp_ID=\"Test\",\n",
    "            write_iterations=1000,\n",
    "            max_iterations=max_iterations,\n",
    "            delta=1e-3,\n",
    "            patience=8,\n",
    "            reg_coef = reg_coef,\n",
    "            k_mse_loss=k_mse_loss\n",
    "            )\n",
    "        print()\n",
    "        #saving model and coefficients\n",
    "        coefs      = np.reshape(model.estimator_coeffs(),(-1,1))\n",
    "        coefs_list.append(coefs)\n",
    "        coef_array = np.asarray(coefs_list)\n",
    "        np.savetxt(f\"{filename}_coefs_run{i}\",np.asarray(model.estimator_coeffs()).reshape(1,-1))\n",
    "        torch.save(model,f\"{filename}_model_run{i}\")\n",
    "        \n",
    "        #plotting and saving errors\n",
    "        rmse,mae,x_array,pred_array = plotting_predictions(number_of_years=20,filename=f\"{filename}_run{i+1}\")\n",
    "        plt.savefig(f\"{filename}_plotrun{i}\")\n",
    "        plt.show()\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    #saving global errors, coefs\n",
    "    np.savetxt(f\"{filename}error\",(rmse_list,mae_list),delimiter = \",\")\n",
    "    np.savetxt(f\"{filename}_mean\",(np.mean(rmse_list),np.mean(mae_list)))\n",
    "\n",
    "\n",
    "    #bar plotting\n",
    "    indices = np.arange(1,coef_array.shape[1]+1)\n",
    "    coiso = -int(coef_array.shape[0]/2)*0.8\n",
    "    plt.figure(figsize=(20,8))\n",
    "    bottom=0\n",
    "    for instance in range(coef_array.shape[0]):\n",
    "        aux = np.asarray(np.abs(coef_array[instance,:]).reshape(coef_array.shape[1]))\n",
    "        if instance == 0:\n",
    "            plt.bar(indices,aux,width=0.8,label=f\"run number={instance+1}\")\n",
    "        else:\n",
    "            plt.bar(indices,aux,width=0.8,bottom=bottom,label=f\"run number={instance+1}\")\n",
    "        bottom += aux\n",
    "\n",
    "    \n",
    "    plt.title(f\"{filename}\")    \n",
    "    plt.xticks(indices)\n",
    "    plt.xlabel(\"Coeficient number\")\n",
    "    plt.ylabel(\"Coeficient magnitude\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'{filename}_bars.png')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859d472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.762457Z",
     "start_time": "2021-10-26T09:28:41.762445Z"
    }
   },
   "outputs": [],
   "source": [
    "training_several_runs(nr_runs=3,max_iterations=3001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c000e28-6569-4627-875a-091a87dc13fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.764513Z",
     "start_time": "2021-10-26T09:28:41.764500Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefs_list       = []\n",
    "ftt_period_list = np.array(frequencies[1:])\n",
    "\n",
    "nr_training_instances = 10\n",
    "rmse_list = []\n",
    "mae_list  = []\n",
    "filename = f\"5n30_w33_k10_sin_5k\"\n",
    "period_list = np.array([0.1, 0.2, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])*365.0\n",
    "p_list_nn = np.array([1.0/12.0, 0.75, 1.0, 1.5, 2.0])*365.0\n",
    "\n",
    "\n",
    "for i in range(nr_training_instances):\n",
    "    network            = Siren(2, 7*[30],1,first_omega_0=3,hidden_omega_0=3)\n",
    "    #network            = SCNN(2,[40,40,40,40],1,p_list =p_list_nn )\n",
    "    library            = CustomLibrary(poly_order=3, diff_order=2,frequencies_list=ftt_period_list)\n",
    "    #library            = Library_nonlinear(period_list=period_list)\n",
    "    #estimator          = Threshold(0.01)\n",
    "    estimator          = PDEFIND()\n",
    "    sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=10, delta=1e-3)\n",
    "    constraint         = LeastSquares()\n",
    "    model              = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "    optimizer          = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=1e-3)\n",
    "    train(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        optimizer,\n",
    "        sparsity_scheduler,\n",
    "        exp_ID=\"Test\",\n",
    "        write_iterations=1000,\n",
    "        max_iterations=5001,\n",
    "        delta=1e-3,\n",
    "        patience=8,\n",
    "        reg_coef = 10,\n",
    "        k_mse_loss=1\n",
    "        )\n",
    "    print()\n",
    "    coefs      = np.reshape(model.estimator_coeffs(),(-1,1))\n",
    "    coefs_list.append(coefs)\n",
    "    coef_array = np.asarray(coefs_list)\n",
    "    np.savetxt(f\"{filename}_coefs_run{i}\",np.asarray(model.estimator_coeffs()).reshape(1,-1))\n",
    "    torch.save(model,f\"{filename}_model_run{i}\")\n",
    "    rmse,mae,x_array,pred_array = plotting_predictions(number_of_years=20,filename=f\"{filename}_run{i+1}\");\n",
    "    plt.savefig(f\"{filename}_plotrun{i}\")\n",
    "    \n",
    "    plt.show()\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "#saving errors, coefs and model\n",
    "np.savetxt(f\"{filename}error\",(rmse_list,mae_list),delimiter = \",\")\n",
    "np.savetxt(f\"{filename}_mean\",(np.mean(rmse_list),np.mean(mae_list)))\n",
    "\n",
    "\n",
    "#bar plotting\n",
    "indices = np.arange(1,coef_array.shape[1]+1)\n",
    "coiso = -int(coef_array.shape[0]/2)*w\n",
    "plt.figure(figsize=(20,8))\n",
    "bottom=0\n",
    "for instance in range(coef_array.shape[0]):\n",
    "    aux = np.asarray(np.abs(coef_array[instance,:]).reshape(coef_array.shape[1]))\n",
    "    if instance == 0:\n",
    "        plt.bar(indices,aux,width=0.8,label=f\"run number={instance+1}\")\n",
    "    else:\n",
    "        plt.bar(indices,aux,width=0.8,bottom=bottom,label=f\"run number={instance+1}\")\n",
    "    bottom += aux\n",
    "\n",
    "    \n",
    "plt.title(f\"{filename}\")    \n",
    "plt.xticks(indices)\n",
    "plt.xlabel(\"Coeficient number\")\n",
    "plt.ylabel(\"Coeficient magnitude\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(f'{filename}_bars.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13796772-ff0f-4927-9f5e-ae001215d8cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bar plot of coeficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f0075-d966-47b6-9c0a-76aba5442726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.766836Z",
     "start_time": "2021-10-26T09:28:41.766823Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I have an array of size ( nr_instances, n_terms, 1) as (layers,rows,columns)\n",
    "# and I want to grab each row from each instance and group them together then do a bar plot\n",
    "\n",
    "w = 0.1\n",
    "indices = np.arange(1,coef_array.shape[1]+1)\n",
    "coiso = 0\n",
    "plt.figure(figsize=(20,8))\n",
    "for instance in range(coef_array.shape[0]):\n",
    "    aux = np.asarray(np.abs(coef_array[instance,:]).reshape(coef_array.shape[1]))\n",
    "    plt.bar(indices+coiso,aux,width=w,label=f\"run number={instance+1}\")\n",
    "    coiso += w\n",
    "plt.xticks(indices)\n",
    "plt.xlabel(\"Coeficient number\")\n",
    "plt.ylabel(\"Coeficient magnitude\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('NN50_w33_k1_sinonly.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c8ca1-aeff-4113-83b1-9cbfd636ac98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.768805Z",
     "start_time": "2021-10-26T09:28:41.768793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb435e0-3814-4168-a4ba-c553883842e9",
   "metadata": {},
   "source": [
    "### Original implementation from Jia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d0b45-5ea4-4be0-854e-0af706c5e35d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.770571Z",
     "start_time": "2021-10-26T09:28:41.770559Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "period_list = np.array([0.1, 0.2, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])*365.0\n",
    "p_list_nn = np.array([1.0/12.0, 0.75, 1.0, 1.5, 2.0])*365.0\n",
    "\n",
    "ftt_period_list = np.array(frequencies)\n",
    "\n",
    "network            = SCNN(2, [40,40,40,40,40],1,p_list=p_list_nn)\n",
    "#network            = Siren(2, [50,50,50,50], 1,first_omega_0=50,hidden_omega_0=50)\n",
    "#network            = NN(2,[50,50,50,50],1)\n",
    "#library            = CustomLibrary(poly_order=4, diff_order=2,period_list=ftt_period_list)\n",
    "library            = Library_nonlinear(period_list = period_list)\n",
    "estimator          = PDEFIND() \n",
    "sparsity_scheduler = TrainTestPeriodic(periodicity=50, patience=200, delta=1e-4)\n",
    "constraint         = LeastSquares()\n",
    "model              = DeepMoD(network, library, estimator, constraint).to(device)\n",
    "optimizer          = torch.optim.Adam(model.parameters(), betas=(0.99, 0.99), amsgrad=True, lr=2e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2981f-cd08-4976-bb22-05bc400e44ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.772706Z",
     "start_time": "2021-10-26T09:28:41.772693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    sparsity_scheduler,\n",
    "    exp_ID=\"Test\",\n",
    "    write_iterations=1000,\n",
    "    max_iterations=10001,\n",
    "    delta=1e-3,\n",
    "    patience=8,\n",
    "    reg_coef = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58106d1-b1bc-4c61-b6e9-8b27a430a53a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.775456Z",
     "start_time": "2021-10-26T09:28:41.775437Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.sparsity_masks)\n",
    "print()\n",
    "\n",
    "#just printing as rows to facilite visualization\n",
    "coefs = np.reshape(model.estimator_coeffs(),(1,-1))\n",
    "print(coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d01a91-1bf4-4281-8958-a768ca5f0f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T09:28:41.777886Z",
     "start_time": "2021-10-26T09:28:41.777873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotting_predictions(number_of_years=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ef3a4-4a2d-4728-9379-71222be2e014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fdbc1a-d9d7-45c1-b880-b94389450f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517202e4-3e91-4395-a7d7-b19421a9250f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f80b4-f608-4465-90b8-ac568aaf07ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
