{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d63500-a7a8-40e2-a92e-5ceddf0288e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.8/site-packages (1.7.7)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.22.2)\n",
      "Requirement already satisfied: torch>=1.9.* in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.11.0a0+17540c5)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (5.4.1)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (0.3.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.0.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2.10.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.26.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.6.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.19.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.35.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (59.5.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.3.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.43.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: comet-ml in /opt/conda/lib/python3.8/site-packages (3.31.15)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (4.4.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (3.0.2)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.20.46)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (1.14.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (1.9.10)\n",
      "Requirement already satisfied: everett[ini]>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (3.0.0)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.57.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (2.26.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from comet-ml) (1.16.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.9.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.8/site-packages (from dulwich!=0.20.33,>=0.20.6->comet-ml) (1.26.12)\n",
      "Requirement already satisfied: configobj in /opt/conda/lib/python3.8/site-packages (from everett[ini]>=1.0.1->comet-ml) (5.0.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (18.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=3.1.0,>=2.6.0->comet-ml) (3.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pytorch-lightning\n",
    "!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29b8a8b-4cec-4121-9b76-54ee1ea056d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of GPUs is: 1\n",
      "GPU number 0 is Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/notebooks\")\n",
    "from pytorch_lightning import LightningModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from base_lightning import Dataset\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "#from neptune.new.types import File\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from sklearn.linear_model import LassoCV,Lasso, LinearRegression\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor,TQDMProgressBar,EarlyStopping\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def gpu_prints():\n",
    "    print(\"The total number of GPUs is:\",torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU number\",i,\"is\",torch.cuda.get_device_name(i))\n",
    "        \n",
    "gpu_prints()\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0824405c-a939-4346-b3b2-de0a1c968bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalActivation(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pi = torch.tensor([math.pi],dtype=torch.float32,device=\"cuda\")\n",
    "    \n",
    "    def forward(self,input): \n",
    "        \n",
    "        sinusoid = torch.sin(2*self.pi*input)\n",
    "        return sinusoid\n",
    "\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden,init=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.init = init\n",
    "        self.network = self.build_network(hidden,sigma=1)\n",
    "        \n",
    "    def forward(self, input_: torch.Tensor):\n",
    "        \n",
    "        input_ = input_.requires_grad_(True)\n",
    "        return self.network(input_),input_\n",
    "\n",
    "    def build_network(self,hidden,sigma):\n",
    "\n",
    "        network= []\n",
    "        first = nn.Linear(2,hidden)\n",
    "        if self.init:\n",
    "            print(\"Initing NN weights and baises\")\n",
    "            nn.init.normal_(first.weight,0,sigma**2)\n",
    "            nn.init.zeros_(first.bias)\n",
    "        network.append(first)\n",
    "        network.append(SinusoidalActivation())\n",
    "        \n",
    "        second = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(second.weight)\n",
    "            torch.nn.init.zeros_(second.bias)\n",
    "        network.append(second)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        third = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(third.weight)\n",
    "            torch.nn.init.zeros_(third.bias)\n",
    "        network.append(third)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        fourth = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(fourth.weight)\n",
    "            torch.nn.init.zeros_(fourth.bias)\n",
    "        network.append(fourth)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        fith = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(fith.weight)\n",
    "            torch.nn.init.zeros_(fith.bias)\n",
    "        network.append(fith)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        sixth = nn.Linear(hidden,1)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(sixth.weight)\n",
    "            torch.nn.init.zeros_(sixth.bias)\n",
    "        network.append(sixth)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        network.pop()\n",
    "        network = nn.Sequential(*network)\n",
    "        \n",
    "        return network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13d7d9c-d58c-41d1-94ac-7c519552856e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularNN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config,init_NN):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data            = np.load(filename)\n",
    "        a = filename.split('/')\n",
    "        self.dir = a[0]\n",
    "        self.filename = a[-1].split('.npz')[0]\n",
    "        \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "\n",
    "\n",
    "        self.X_train         = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "\n",
    "        self.Y_train         = self.total_Y[self.total_X[:,0]<=2]\n",
    "        self.Y_validation    = self.total_Y[self.total_X[:,0]>=2]\n",
    "\n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "\n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "\n",
    "        self.coiso              = None\n",
    "        self.xi                 = None\n",
    "        self.analytical_du2_dx2 = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.network            = custom_NN(n_in=2,n_hidden=6*[60],n_out=1,init=init_NN)\n",
    "        \n",
    "        self.first_coeff  = -(self.c**2-self.v**2)\n",
    "        self.second_coeff = +2*self.v\n",
    "        \n",
    "        print(\"1st coef:\",self.first_coeff)\n",
    "        print(\"2nd coef:\",self.second_coeff)\n",
    "    \n",
    "    def fig2img(self,fig):\n",
    "        \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def forward(self,input_):\n",
    "\n",
    "        return self.network(input_)\n",
    "\n",
    "    def on_train_start(self):\n",
    "\n",
    "        print(\"Device is:\",self.device)\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=\"Real Wave\")\n",
    "        plt.close()\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "\n",
    "        #forward pass\n",
    "        x,target = batch\n",
    "        prediction,coordinates = self.forward(x)\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction,coordinates) # derivatives\n",
    "\n",
    "        #self.xi = self.least_squares_QR(theta,second_time_deriv) #sparse vector computed using least squares\n",
    "        self.xi = self.least_squares_SK(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction-target)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv+term1+term2)**2)#should be scalar as well\n",
    "        total_loss                          = mse_loss + self.k_pde*pde_loss\n",
    "\n",
    "        #for i,j in enumerate(xi):\n",
    "        #   self.log(f\"Coefficient nr{i}\",j,logger=True,on_epoch=True,on_step=False)\n",
    "        \n",
    "        self.log(f\"Coefficient nr1\",-self.xi[0],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Coefficient nr2\",-self.xi[1],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr1\",torch.abs((-self.xi[0]-self.first_coeff)/self.first_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr2\",torch.abs((-self.xi[1]-self.second_coeff)/self.second_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "    \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "\n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "        \n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "        \n",
    "        \n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        #term1 = -(self.c**2-self.v**2)*du2_dx2\n",
    "        #term2 = +2*self.v*du2_dtdx\n",
    "\n",
    "        term1 = du2_dx2\n",
    "        term2 = du2_dtdx\n",
    "        \n",
    "\n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "\n",
    "            return second_time_deriv,theta,term1,term2\n",
    "\n",
    "        else:\n",
    "\n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "\n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def least_squares_SK(self,theta,second_time_deriv):\n",
    "        \n",
    "        x,y = theta.detach().cpu().numpy(), second_time_deriv.detach().cpu().detach()\n",
    "        coefs = LinearRegression().fit(x,y).coef_\n",
    "        return coefs[0]\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-8)\n",
    "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(mode=\"min\",factor=0.5,patience=500,threshold_mode=\"rel\",threshold=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset    = Dataset(data=self.X_train, labels=self.Y_train)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(self.X_train.shape[0]/6),drop_last=True, num_workers=0, shuffle=True)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=int(self.X_validation.shape[0]/6),\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "        \n",
    "        return val_dataloader\n",
    "\n",
    "    def analytical_derivs(self,x,time):\n",
    "\n",
    "        if self.coiso is None:\n",
    "\n",
    "            self.omega = np.zeros(self.coefs.shape[0])\n",
    "            self.k_rev = np.zeros(self.coefs.shape[0])\n",
    "            self.k_fwd = np.zeros(self.coefs.shape[0])\n",
    "            self.phi   = np.zeros(self.coefs.shape[0])\n",
    "            self.coiso = 1\n",
    "\n",
    "            for i in range(self.coefs.shape[0]):\n",
    "\n",
    "                n = i+1\n",
    "                self.omega[i] = n*np.pi*(self.c**2-self.v**2)/self.c\n",
    "                self.k_rev[i] = n*np.pi*(self.c+self.v)/self.c\n",
    "                self.k_fwd[i] = n*np.pi*(self.c-self.v)/self.c\n",
    "                self.phi[i]   = -n*(np.pi*(self.c+self.v)/(2*self.c)-np.pi/2)\n",
    "\n",
    "\n",
    "\n",
    "        du2_dx2  = np.zeros((len(time),len(x)))\n",
    "        du2_dxdt = np.zeros((len(time),len(x)))\n",
    "        du2_dt2  = np.zeros((len(time),len(x)))\n",
    "\n",
    "        for b,t in enumerate(time):\n",
    "\n",
    "            sum1  = 0\n",
    "            sum2  = 0\n",
    "            sum3  = 0\n",
    "\n",
    "            for n in range(self.coefs.shape[0]):\n",
    "\n",
    "                C1     = self.coefs[n] * np.sin(self.k_fwd[n]*x - self.omega[n]*t - self.phi[n])\n",
    "                C2     = self.coefs[n] * np.sin(self.k_rev[n]*x + self.omega[n]*t + self.phi[n])\n",
    "\n",
    "                sum1 += -self.k_fwd[n]**2*C1 - self.k_rev[n]**2*C2\n",
    "                sum2 += +self.k_fwd[n]*self.omega[n]*C1  - self.k_rev[n]*self.omega[n]*C2\n",
    "                sum3 += -self.omega[n]**2*C1 - self.omega[n]**2*C2\n",
    "\n",
    "            du2_dx2[b,:]  = sum1\n",
    "            du2_dxdt[b,:] = sum2\n",
    "            du2_dt2[b,:]  = sum3\n",
    "\n",
    "        #this analytical derivatives should be [T,X]\n",
    "        return du2_dx2,du2_dxdt,du2_dt2\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "\n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Full predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Full predicted wave\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Difference between true wave and predicted wave\")\n",
    "        plt.close()\n",
    "\n",
    "    def anim(self):\n",
    "\n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "\n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "\n",
    "        plt.legend()\n",
    "        anim.save(f\"{self.dir}/predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",writer=PillowWriter(fps=24))\n",
    "        #image = self.fig2img(anim)\n",
    "        #self.logger.experiment.log_image(image,name=f\"Prediction fig at {self.current_epoch}\")\n",
    "        plt.close()\n",
    "        self.logger.experiment.log_image(f\"{self.dir}/predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",name=f\"Prediction gif at {self.current_epoch}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        self.plot()\n",
    "        self.anim()\n",
    "      \n",
    "        \"\"\"with torch.enable_grad():\n",
    "            predictions,coordinates = self.forward(self.X_train.to(self.device))\n",
    "\n",
    "            #analytical derivatives--> stay constant only need to compute 1 time\n",
    "            if self.analytical_du2_dx2 == None:\n",
    "                self.analy_du2_dx2,self.analy_du2_dxdt,self.analy_du2_dt2 = self.analytical_derivs(self.total_x,self.T[self.T<=2])\n",
    "\n",
    "            #auto diff derivatives\n",
    "            NN_du2_dt2,NN_du2_dxdt,NN_du2_dx2          = self.compute_derivatives(predictions,coordinates,derivs=True)\n",
    "\n",
    "        NN_du2_dt2 = NN_du2_dt2.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "        NN_du2_dxdt= NN_du2_dxdt.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "        NN_du2_dx2 = NN_du2_dx2.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "\n",
    "        dif1 = 100 * np.median(np.abs((NN_du2_dt2[self.analy_du2_dt2>1e-5]  - self.analy_du2_dt2[self.analy_du2_dt2>1e-5])/self.analy_du2_dt2[self.analy_du2_dt2>1e-5]))\n",
    "        dif2 = 100 * np.median(np.abs((NN_du2_dx2[self.analy_du2_dx2>1e-5]  - self.analy_du2_dx2[self.analy_du2_dx2>1e-5])/self.analy_du2_dx2[self.analy_du2_dx2>1e-5]))\n",
    "        dif3 = 100 * np.median(np.abs((NN_du2_dxdt[self.analy_du2_dxdt>1e-5] - self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5])/self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5]))\n",
    "\n",
    "        abs_dif1 = np.mean(np.abs(NN_du2_dt2 - self.analy_du2_dt2))\n",
    "        abs_dif2 = np.mean(np.abs(NN_du2_dx2 - self.analy_du2_dx2))\n",
    "        abs_dif3 = np.mean(np.abs(NN_du2_dxdt- self.analy_du2_dxdt))\n",
    "\n",
    "        self.log(\"Absolute Diff1\",abs_dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff1\",dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dt2\",np.mean(np.abs(NN_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dt2\",np.mean(np.abs(self.analy_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "        self.log(\"Absolute Diff2\",abs_dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff2\",dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dx2\",np.mean(np.abs(NN_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dx2\",np.mean(np.abs(self.analy_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "        self.log(\"Absolute Diff3\",abs_dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff3\",dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dxdt\",np.mean(np.abs(NN_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dxdt\",np.mean(np.abs(self.analy_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\"\"\"\n",
    "\n",
    " \n",
    "\n",
    "    def update_plot(self,i,line1,line2):\n",
    "\n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07909923-59c1-4612-b4d1-6187d6e5f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data            = np.load(filename)\n",
    "        a = filename.split('/')\n",
    "        self.dir = a[0]\n",
    "        self.filename = a[-1].split('.npz')[0]\n",
    "        \n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.first_coeff  = -(self.c**2-self.v**2)\n",
    "        self.second_coeff = +2*self.v\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "        \n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "        \n",
    "        self.initial_xi         = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.k_mse              = config[\"k_mse\"]\n",
    "        self.network            = NN(init=False,hidden=50)\n",
    "        \n",
    "        \n",
    "         \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "\n",
    "        \n",
    "        self.X1              = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.Y1              = self.total_Y[self.total_X[:,0]<=2]\n",
    "        self.network.to(\"cuda:0\")\n",
    " \n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "        self.Y_validation    = self.total_Y[self.X_validation.shape[0]:]\n",
    "        \n",
    "        self.X_fixed_points  = self.X_validation[(self.X_validation[:,1]== 0)  |\n",
    "                                                 (self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 (self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                ]\n",
    "        \n",
    "        self.Y_fixed_points  = self.Y_validation[(self.X_validation[:,1]== 0) |\n",
    "                                                 (self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 (self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                 ]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.X_MSE           = self.X_fixed_points\n",
    "        self.Y_MSE           = self.Y_fixed_points\n",
    "        \n",
    "    \n",
    "        print(\"1st coef:\",self.first_coeff)\n",
    "        print(\"2nd coef:\",self.second_coeff)\n",
    "\n",
    "        \n",
    "    def fig2img(self,fig):\n",
    "        \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        return img\n",
    "        \n",
    "    def forward(self,input_):\n",
    "                \n",
    "        return self.network(input_)\n",
    "    \n",
    "    def on_fit_start(self):      \n",
    "        \n",
    "        self.initial_xi = [1,1]\n",
    "        aux1,aux2 = self.forward(self.X1.to(device='cuda:0'))\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(aux1,aux2)\n",
    "        self.initial_xi = self.least_squares_QR(theta,second_time_deriv).detach()\n",
    "        print(self.initial_xi)\n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        image=self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=\"Real Wave\")     \n",
    "        self.anim()\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "        \n",
    "        #forward pass\n",
    "        batch1 = batch[\"mse\"]\n",
    "        batch2 = batch[\"pde\"]\n",
    "\n",
    "        x1,target1 = batch1\n",
    "        x2,target2 = batch2\n",
    "\n",
    "        prediction1,coordinates1 = self.forward(x1)\n",
    "        prediction2,coordinates2 = self.forward(x2)\n",
    "\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction2,coordinates2)\n",
    "        self.xi = self.least_squares_QR(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction1-target1)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv-(term1+term2))**2)#should be scalar as well\n",
    "        total_loss                          = self.k_mse*mse_loss  + self.k_pde*pde_loss\n",
    "\n",
    "\n",
    "        self.log(f\"Coefficient nr1\",self.xi[0],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Coefficient nr2\",self.xi[1],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr1\",torch.abs((self.xi[0]-self.first_coeff)/self.first_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr2\",torch.abs((self.xi[1]-self.second_coeff)/self.second_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "    \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)      \n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "        \n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "\n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "\n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        term1 = self.initial_xi[0]*du2_dx2\n",
    "        term2 = self.initial_xi[1]*du2_dtdx\n",
    "\n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "\n",
    "            return second_time_deriv,theta,term1,term2\n",
    "\n",
    "        else:\n",
    "\n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "\n",
    "        \n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "\n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-8)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset1   = Dataset(data=self.X_MSE, labels=self.Y_MSE)\n",
    "        dataset2   = Dataset(data=self.X_validation,labels = self.Y_validation)\n",
    "\n",
    "        dataloader1 = torch.utils.data.DataLoader(dataset1, batch_size=int(self.X_MSE.shape[0]/4),drop_last=True, shuffle=True,num_workers=0)\n",
    "        dataloader2 = torch.utils.data.DataLoader(dataset2, batch_size=int(self.X_validation.shape[0]/4),drop_last=True,shuffle=True,num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "        return {\"mse\":dataloader1,\"pde\":dataloader2}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=int(self.X_validation.shape[0]/4),\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "\n",
    "        return val_dataloader\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        \n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Full predicted wave\")\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Difference between true wave and predicted wave\")\n",
    "        plt.close()\n",
    "    \n",
    "    def anim(self):\n",
    "        \n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "        \n",
    "        plt.legend()\n",
    "        writergif = animation.PillowWriter(fps=30)\n",
    "\n",
    "        anim.save(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",writer=\"ffmpeg\")\n",
    "        plt.close()\n",
    "        self.logger.experiment.log_image(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",name=f\"Prediction gif at {self.current_epoch}\")\n",
    "    \n",
    "    def update_plot(self,i,line1,line2):\n",
    "        \n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)\n",
    "        \n",
    "        return lines    \n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        self.plot()\n",
    "        self.anim()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e027d9b-08c1-48c0-ad98-c429ace5fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def training(filename,PATH):\n",
    "    \n",
    "    print(filename)\n",
    "    save_name = filename.split(\"/\")[-1]\n",
    "    save_name = save_name.split(\".npz\")[0]\n",
    "\n",
    "    config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"filename\":filename,\n",
    "        \"k_pde\":1e-4,\n",
    "        \"k_mse\":1,\n",
    "        \"PATH\":PATH\n",
    "    } \n",
    "    \n",
    "    model = PINN(filename=filename,config=config)\n",
    "    model.load_from_checkpoint(filename=filename,config=config,checkpoint_path=config[\"PATH\"])\n",
    "    model.to(\"cuda:0\")\n",
    "    print(model)\n",
    "    \n",
    "\n",
    "    comet_logger = CometLogger(\n",
    "        api_key=\"kZhkiprqabfgQqOTbHNHpOJvf\",\n",
    "        workspace=\"jose-bastos\",\n",
    "        project_name=\"noise-pinn\"  # Optional\n",
    "    )\n",
    "\n",
    "    comet_logger.log_hyperparams(config)\n",
    "    \n",
    "    epochs = 20\n",
    "    epochs = epochs*10**3+1\n",
    "    kwargs = {\"max_epochs\":epochs ,\n",
    "              \"accelerator\": \"gpu\",\n",
    "              \"devices\":1,\n",
    "              \"num_sanity_val_steps\": 0,\n",
    "              \"logger\": comet_logger,\n",
    "              \"check_val_every_n_epoch\":1000,\n",
    "              \"enable_checkpointing\":False,\n",
    "              \"enable_progress_bar\":False\n",
    "             }\n",
    "\n",
    "    trainer = Trainer(**kwargs,resume_from_checkpoint=config[\"PATH\"])\n",
    "    trainer.fit(model)\n",
    "    trainer.save_checkpoint(f\"resolution/models/PINNs/spatial/{save_name}_{epochs}k_nofixedpoints.ckpt\")\n",
    "\n",
    "    \n",
    "    comet_logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077bbe5-299f-46ff-8470-ad814f85bf55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7010424-8d46-41b5-bf95-147e7684dce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise/data/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/88b8fd1f05c041f2b5a44fc96c1b31be\n",
      "\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:52: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:731: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  ckpt_path = ckpt_path or self.resume_from_checkpoint\n",
      "Restoring states from the checkpoint path at Noise/models/NN/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | NN   | 10.4 K\n",
      "---------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7339],\n",
      "        [-0.9595]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "COMET WARNING: Error exporting current conda environment\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "Restored all states from the checkpoint file at Noise/models/NN/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:98: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 200. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "`Trainer.fit` stopped: `max_epochs=20001` reached.\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/resolution-pinn/88b8fd1f05c041f2b5a44fc96c1b31be\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Coefficient nr1 [5000]          : (0.4806877076625824, 1.0330212116241455)\n",
      "COMET INFO:     Coefficient nr2 [5000]          : (0.06898564100265503, 1.027299404144287)\n",
      "COMET INFO:     Error in coefficient nr1 [5000] : (164.09170532226562, 237.73617553710938)\n",
      "COMET INFO:     Error in coefficient nr2 [5000] : (0.15631914138793945, 93.10144805908203)\n",
      "COMET INFO:     MSE Loss [5000]                 : (3.02246608043788e-05, 1.5069050788879395)\n",
      "COMET INFO:     PDE Loss [5000]                 : (1.5529108047485352, 9945.0693359375)\n",
      "COMET INFO:     Total Loss [5000]               : (0.00019791178056038916, 2.5014121532440186)\n",
      "COMET INFO:     Validation Loss [5]             : (0.00043817440746352077, 0.0006841051508672535)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     PATH     : Noise/models/NN/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "COMET INFO:     filename : Noise/data/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n",
      "COMET INFO:     k_mse    : 1\n",
      "COMET INFO:     k_pde    : 0.0001\n",
      "COMET INFO:     lr       : 0.001\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (16.91 MB)\n",
      "COMET INFO:     images                   : 17\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/88b8fd1f05c041f2b5a44fc96c1b31be\n",
      "\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/resolution-pinn/88b8fd1f05c041f2b5a44fc96c1b31be\n",
      "COMET INFO: -----------------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading 2 metrics, params and output messages\n",
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise/data/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/63498e3c32984ecb8a261d3cdeb22af2\n",
      "\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:52: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:731: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  ckpt_path = ckpt_path or self.resume_from_checkpoint\n",
      "Restoring states from the checkpoint path at Noise/models/NN/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | NN   | 10.4 K\n",
      "---------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7357],\n",
      "        [-0.9638]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "COMET WARNING: Error exporting current conda environment\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "Restored all states from the checkpoint file at Noise/models/NN/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "`Trainer.fit` stopped: `max_epochs=20001` reached.\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/resolution-pinn/63498e3c32984ecb8a261d3cdeb22af2\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Coefficient nr1 [5000]          : (0.46806877851486206, 1.0187058448791504)\n",
      "COMET INFO:     Coefficient nr2 [5000]          : (-0.014586428180336952, 1.0258845090866089)\n",
      "COMET INFO:     Error in coefficient nr1 [5000] : (162.40916442871094, 235.82745361328125)\n",
      "COMET INFO:     Error in coefficient nr2 [5000] : (0.11943875998258591, 101.4586410522461)\n",
      "COMET INFO:     MSE Loss [5000]                 : (0.00017825333634391427, 1.1846085786819458)\n",
      "COMET INFO:     PDE Loss [5000]                 : (1.2311252355575562, 5642.42138671875)\n",
      "COMET INFO:     Total Loss [5000]               : (0.00031208101427182555, 1.748850703239441)\n",
      "COMET INFO:     Validation Loss [5]             : (0.0007642910350114107, 0.0009122054325416684)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     PATH     : Noise/models/NN/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "COMET INFO:     filename : Noise/data/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n",
      "COMET INFO:     k_mse    : 1\n",
      "COMET INFO:     k_pde    : 0.0001\n",
      "COMET INFO:     lr       : 0.001\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (16.92 MB)\n",
      "COMET INFO:     images                   : 17\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/63498e3c32984ecb8a261d3cdeb22af2\n",
      "\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/resolution-pinn/63498e3c32984ecb8a261d3cdeb22af2\n",
      "COMET INFO: -----------------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading 2 metrics, params and output messages\n",
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise/data/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/92ddcc32a60b432183cb0df061e2f47c\n",
      "\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:52: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:731: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  ckpt_path = ckpt_path or self.resume_from_checkpoint\n",
      "Restoring states from the checkpoint path at Noise/models/NN/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | NN   | 10.4 K\n",
      "---------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7128],\n",
      "        [-0.9147]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "COMET WARNING: Error exporting current conda environment\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "Restored all states from the checkpoint file at Noise/models/NN/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "`Trainer.fit` stopped: `max_epochs=20001` reached.\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/resolution-pinn/92ddcc32a60b432183cb0df061e2f47c\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Coefficient nr1 [5000]          : (0.4623008370399475, 1.0439085960388184)\n",
      "COMET INFO:     Coefficient nr2 [5000]          : (0.28642594814300537, 1.062921166419983)\n",
      "COMET INFO:     Error in coefficient nr1 [5000] : (161.64012145996094, 239.18780517578125)\n",
      "COMET INFO:     Error in coefficient nr2 [5000] : (0.21979808807373047, 71.35740661621094)\n",
      "COMET INFO:     MSE Loss [5000]                 : (0.0007296472322195768, 0.711564302444458)\n",
      "COMET INFO:     PDE Loss [5000]                 : (7.575458526611328, 7090.54248046875)\n",
      "COMET INFO:     Total Loss [5000]               : (0.0015463605523109436, 1.4206185340881348)\n",
      "COMET INFO:     Validation Loss [5]             : (0.002479767659679055, 0.002949101384729147)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     PATH     : Noise/models/NN/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "COMET INFO:     filename : Noise/data/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n",
      "COMET INFO:     k_mse    : 1\n",
      "COMET INFO:     k_pde    : 0.0001\n",
      "COMET INFO:     lr       : 0.001\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (16.92 MB)\n",
      "COMET INFO:     images                   : 17\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/92ddcc32a60b432183cb0df061e2f47c\n",
      "\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO: Comet.ml ExistingExperiment Summary\n",
      "COMET INFO: -----------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/resolution-pinn/92ddcc32a60b432183cb0df061e2f47c\n",
      "COMET INFO: -----------------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading 2 metrics, params and output messages\n",
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise/data/c=1_v=0.5c_noise=0.25_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/resolution-pinn/f46d8a57bae3452ab302c5eae1509f97\n",
      "\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:52: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:731: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  ckpt_path = ckpt_path or self.resume_from_checkpoint\n",
      "Restoring states from the checkpoint path at Noise/models/NN/c=1_v=0.5c_noise=0.25_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | NN   | 10.4 K\n",
      "---------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6578],\n",
      "        [-0.8279]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "COMET WARNING: Error exporting current conda environment\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "Restored all states from the checkpoint file at Noise/models/NN/c=1_v=0.5c_noise=0.25_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "files = [\"Noise/data/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\",\n",
    "         \"Noise/data/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\",\n",
    "         \"Noise/data/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\",\n",
    "         \"Noise/data/c=1_v=0.5c_noise=0.25_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\",\n",
    "         \"Noise/data/c=1_v=0.5c_noise=0.5_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\"]\n",
    "\n",
    "paths = [\"Noise/models/NN/c=1_v=0.5c_noise=0.01_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\",\n",
    "         \"Noise/models/NN/c=1_v=0.5c_noise=0.05_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\",\n",
    "         \"Noise/models/NN/c=1_v=0.5c_noise=0.1_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\",\n",
    "         \"Noise/models/NN/c=1_v=0.5c_noise=0.25_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\",\n",
    "         \"Noise/models/NN/c=1_v=0.5c_noise=0.5_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\"]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    training(filename = files[i],PATH=paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6385ad2-8b96-42af-b999-7c3d15b05ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
