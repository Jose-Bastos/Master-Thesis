{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5830faa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T16:50:33.616777Z",
     "start_time": "2022-06-14T16:50:31.472130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105478/2973309721.py:5: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of GPUs is: 2\n",
      "GPU number 0 is NVIDIA GeForce GTX 1080 Ti\n",
      "GPU number 1 is NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gif\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from deepymod.data.base_lightning import Dataset\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from neptune.new.types import File\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.linear_model import LassoCV,Lasso\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor,TQDMProgressBar,EarlyStopping\n",
    "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
    "\n",
    "\n",
    "def gpu_prints():\n",
    "    print(\"The total number of GPUs is:\",torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU number\",i,\"is\",torch.cuda.get_device_name(i))\n",
    "        \n",
    "gpu_prints()\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36db8dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T16:50:33.662703Z",
     "start_time": "2022-06-14T16:50:33.618981Z"
    }
   },
   "outputs": [],
   "source": [
    "class SinusoidalActivation(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pi = torch.tensor([math.pi],dtype=torch.float32,device=\"cpu\")\n",
    "    \n",
    "    def forward(self,input):\n",
    "        \n",
    "        sinusoid = torch.sin(2*self.pi*input)\n",
    "        return sinusoid\n",
    "    \n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, n_in: int, n_hidden, n_out: int,init: bool) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.init = init\n",
    "        self.network = self.build_network(n_in, n_hidden, n_out)\n",
    "        \n",
    "    def forward(self, input_: torch.Tensor):\n",
    "        \n",
    "        input_ = input_.requires_grad_(True)\n",
    "        return self.network(input_),input_\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "            \n",
    "\n",
    "    def build_network(self, n_in, n_hidden, n_out):\n",
    "\n",
    "        network = []\n",
    "        architecture = [n_in] + n_hidden + [n_out]\n",
    "        count = 0\n",
    "        for layer_i, layer_j in zip(architecture, architecture[1:]):\n",
    "            network.append(nn.Linear(layer_i, layer_j))\n",
    "            if count ==0:\n",
    "                network.append(SinusoidalActivation())\n",
    "            else:\n",
    "                network.append(nn.Tanh())\n",
    "            count+=1\n",
    "        network.pop()  # get rid of last activation function\n",
    "        network = nn.Sequential(*network)\n",
    "        if self.init == True:\n",
    "            network.apply(self.init_weights)\n",
    "        return network\n",
    "    \n",
    "class PINN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config):\n",
    "\n",
    "        super().__init__()\n",
    "        self.filename        = filename\n",
    "        self.data            = np.load(f\"string_data/\" + self.filename + \".npz\")\n",
    "        \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "        \n",
    "        self.X1              = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.Y1              = self.total_Y[self.total_X[:,0]<=2]\n",
    "        \n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "        self.Y_validation    = self.total_Y[self.X_validation.shape[0]:]\n",
    "        \n",
    "        self.X_fixed_points  = self.X_validation[(self.X_validation[:,1]== 0)  |\n",
    "                                                 #(self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 #(self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                ]\n",
    "        \n",
    "        self.Y_fixed_points  = self.Y_validation[(self.X_validation[:,1]== 0) |\n",
    "                                                 #(self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 #(self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                 ]\n",
    "        \n",
    "        self.X_MSE           = self.X_fixed_points\n",
    "        self.Y_MSE           = self.Y_fixed_points\n",
    "        #self.X_MSE           = torch.cat((self.X1,self.X_fixed_points),dim=0)\n",
    "        #self.Y_MSE           = torch.cat((self.Y1,self.Y_fixed_points),dim=0)\n",
    "        \n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "        \n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "        \n",
    "        self.coiso              = None\n",
    "        self.xi                 = None\n",
    "        self.analytical_du2_dx2 = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.k_mse              = config[\"k_mse\"]\n",
    "        self.network            = NN(n_in=2,n_hidden=4*[50],n_out=1,init=False)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,input_):\n",
    "                \n",
    "        return self.network(input_)\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        self.logger.experiment[\"images/\"].log(File.as_image(fig))\n",
    "        plt.close()\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "\n",
    "        #forward pass\n",
    "        batch1 = batch[\"mse\"]\n",
    "        batch2 = batch[\"pde\"]\n",
    "        \n",
    "        x1,target1 = batch1\n",
    "        x2,target2 = batch2\n",
    "\n",
    "        prediction1,coordinates1 = self.forward(x1)\n",
    "        prediction2,coordinates2 = self.forward(x2)\n",
    "        \n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction2,coordinates2)\n",
    "        \n",
    "        xi = self.least_squares_QR(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction1-target1)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv+term1+term2)**2)#should be scalar as well \n",
    "        total_loss                          = self.k_mse*mse_loss  + self.k_pde*pde_loss\n",
    "\n",
    "        for i,j in enumerate(xi):\n",
    "            self.log(f\"Coefficient nr{i}\",j,logger=True,on_epoch=True,on_step=False)\n",
    "        \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)      \n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "        \n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "\n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "\n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        term1 = -(self.c**2-self.v**2)*du2_dx2\n",
    "        term2 = +2*self.v*du2_dtdx\n",
    "    \n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "        \n",
    "            return second_time_deriv,theta,term1,term2\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "        \n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "        \n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-6)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset    = Dataset(data=self.X_MSE, labels=self.Y_MSE)\n",
    "        dataset2   = Dataset(data=self.X_validation,labels = self.Y_validation)\n",
    "        \n",
    "        dataloader1 = torch.utils.data.DataLoader(dataset, batch_size=self.X_MSE.shape[0],drop_last=True, shuffle=True,num_workers=0)\n",
    "        dataloader2 = torch.utils.data.DataLoader(dataset2, batch_size=self.X_validation.shape[0],drop_last=True,shuffle=True,num_workers=0)\n",
    "      \n",
    "        \n",
    "        \n",
    "        return {\"mse\":dataloader1,\"pde\":dataloader2}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=self.X_validation.shape[0],\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "\n",
    "        return val_dataloader\n",
    "    \n",
    "    def analytical_derivs(self,x,time):\n",
    "\n",
    "        if self.coiso is None:\n",
    "\n",
    "            self.omega = np.zeros(self.coefs.shape[0])\n",
    "            self.k_rev = np.zeros(self.coefs.shape[0])\n",
    "            self.k_fwd = np.zeros(self.coefs.shape[0])\n",
    "            self.phi   = np.zeros(self.coefs.shape[0])\n",
    "            self.coiso = 1\n",
    "\n",
    "            for i in range(self.coefs.shape[0]):\n",
    "\n",
    "                n = i+1\n",
    "                self.omega[i] = n*np.pi*(self.c**2-self.v**2)/self.c                \n",
    "                self.k_rev[i] = n*np.pi*(self.c+self.v)/self.c\n",
    "                self.k_fwd[i] = n*np.pi*(self.c-self.v)/self.c\n",
    "                self.phi[i]   = -n*(np.pi*(self.c+self.v)/(2*self.c)-np.pi/2)\n",
    "\n",
    "\n",
    "\n",
    "        du2_dx2  = np.zeros((len(time),len(x)))\n",
    "        du2_dxdt = np.zeros((len(time),len(x)))\n",
    "        du2_dt2  = np.zeros((len(time),len(x)))\n",
    "\n",
    "        for b,t in enumerate(time):\n",
    "\n",
    "            sum1  = 0\n",
    "            sum2  = 0\n",
    "            sum3  = 0\n",
    "\n",
    "            for n in range(self.coefs.shape[0]):\n",
    "\n",
    "                C1     = self.coefs[n] * np.sin(self.k_fwd[n]*x - self.omega[n]*t - self.phi[n])\n",
    "                C2     = self.coefs[n] * np.sin(self.k_rev[n]*x + self.omega[n]*t + self.phi[n])\n",
    "\n",
    "                sum1 += -self.k_fwd[n]**2*C1 - self.k_rev[n]**2*C2\n",
    "                sum2 += +self.k_fwd[n]*self.omega[n]*C1  - self.k_rev[n]*self.omega[n]*C2\n",
    "                sum3 += -self.omega[n]**2*C1 - self.omega[n]**2*C2\n",
    "\n",
    "            du2_dx2[b,:]  = sum1\n",
    "            du2_dxdt[b,:] = sum2\n",
    "            du2_dt2[b,:]  = sum3\n",
    "\n",
    "        #this analytical derivatives should be [T,X]\n",
    "        return du2_dx2,du2_dxdt,du2_dt2\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        \n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Full predicted wave at epoch {self.current_epoch}\")\n",
    "        self.logger.experiment[\"images/\"].log(File.as_image(fig))\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        self.logger.experiment[\"images/\"].log(File.as_image(fig))\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "    def anim(self):\n",
    "        \n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "                \n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "        \n",
    "        plt.legend()\n",
    "        anim.save(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",fps=30,writer=\"ffmpeg\")\n",
    "        plt.close()\n",
    "        self.logger.experiment[\"images/\"].log(File(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\"))\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "#         if self.current_epoch%50 == 0:\n",
    "#             with torch.enable_grad():\n",
    "\n",
    "#                 predictions,coordinates = self.forward(self.X_train.to(self.device))\n",
    "\n",
    "#                 #analytical derivatives--> stay constant only need to compute 1 time\n",
    "#                 if self.analytical_du2_dx2 == None:\n",
    "\n",
    "#                     self.analy_du2_dx2,self.analy_du2_dxdt,self.analy_du2_dt2 = self.analytical_derivs(self.total_x,self.T[self.T<=2])\n",
    "                    \n",
    "#                 #auto diff derivatives\n",
    "#                 NN_du2_dt2,NN_du2_dxdt,NN_du2_dx2          = self.compute_derivatives(predictions,coordinates,derivs=True)\n",
    "#                 second_time_deriv,theta,term1,term2        = self.compute_derivatives(predictions,coordinates)\n",
    "\n",
    "\n",
    "#             self.xi = torch.linalg.lstsq(theta,second_time_deriv).solution        \n",
    "#             for i,j in enumerate(self.xi):\n",
    "#                 self.log(f\"Coefficient nr{i}\",j,logger=True,on_epoch=True,on_step=False)\n",
    "\n",
    "#             NN_du2_dt2 = NN_du2_dt2.detach().cpu().numpy().reshape(int(self.T.shape[0]/2),self.total_x.shape[0])\n",
    "#             NN_du2_dxdt= NN_du2_dxdt.detach().cpu().numpy().reshape(int(self.T.shape[0]/2),self.total_x.shape[0])\n",
    "#             NN_du2_dx2 = NN_du2_dx2.detach().cpu().numpy().reshape(int(self.T.shape[0]/2),self.total_x.shape[0])\n",
    "\n",
    "\n",
    "#             dif1 = 100 * np.median(np.abs((NN_du2_dt2[self.analy_du2_dt2>1e-5]  - self.analy_du2_dt2[self.analy_du2_dt2>1e-5])/self.analy_du2_dt2[self.analy_du2_dt2>1e-5]))        \n",
    "#             dif2 = 100 * np.median(np.abs((NN_du2_dx2[self.analy_du2_dx2>1e-5]  - self.analy_du2_dx2[self.analy_du2_dx2>1e-5])/self.analy_du2_dx2[self.analy_du2_dx2>1e-5]))\n",
    "#             dif3 = 100 * np.median(np.abs((NN_du2_dxdt[self.analy_du2_dxdt>1e-5] - self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5])/self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5]))\n",
    "\n",
    "#             abs_dif1 = np.mean(np.abs(NN_du2_dt2 - self.analy_du2_dt2))\n",
    "#             abs_dif2 = np.mean(np.abs(NN_du2_dx2 - self.analy_du2_dx2))\n",
    "#             abs_dif3 = np.mean(np.abs(NN_du2_dxdt- self.analy_du2_dxdt))\n",
    "\n",
    "\n",
    "#             self.log(\"Absolute Diff1\",abs_dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "#             self.log(\"Relative Diff1\",dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "#             self.log(\"NN_du2_dt2\",np.mean(np.abs(NN_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)    \n",
    "#             self.log(\"Analy_du2_dt2\",np.mean(np.abs(self.analy_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)    \n",
    "\n",
    "\n",
    "#             self.log(\"Absolute Diff2\",abs_dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "#             self.log(\"Relative Diff2\",dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "#             self.log(\"NN_du2_dx2\",np.mean(np.abs(NN_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "#             self.log(\"Analy_du2_dx2\",np.mean(np.abs(self.analy_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "\n",
    "\n",
    "#             self.log(\"Absolute Diff3\",abs_dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "#             self.log(\"Relative Diff3\",dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "#             self.log(\"NN_du2_dxdt\",np.mean(np.abs(NN_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "#             self.log(\"Analy_du2_dxdt\",np.mean(np.abs(self.analy_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "\n",
    "        \n",
    "        if (self.current_epoch%500 == 0):\n",
    "            self.plot()\n",
    "            self.anim()\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "            \n",
    "    def update_plot(self,i,line1,line2):\n",
    "        \n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)\n",
    "        \n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996e4fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T16:50:33.702183Z",
     "start_time": "2022-06-14T16:50:33.663977Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"c=1_v=0.3c_noise=0.0_modes=0.39_0.26_t_final=10_nr=1000\"\n",
    "\n",
    "config = {\n",
    "    \"lr\" :1e-3,\n",
    "    \"filename\":filename,\n",
    "    \"k_pde\":0.01,\n",
    "    \"k_mse\":5\n",
    "}\n",
    "\n",
    "\n",
    "PATH = \"models/PINN/Boundary_only_PIPE220.ckpt\"\n",
    "model = PINN.load_from_checkpoint(PATH,filename=filename,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c6a0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T16:50:33.748771Z",
     "start_time": "2022-06-14T16:50:33.703539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01588874  0.03471116  0.05386645 ... -0.00357217 -0.00489361\n",
      "  -0.00639827]\n",
      " [ 0.01331375  0.03309936  0.05322064 ... -0.00153685 -0.00343335\n",
      "  -0.00552232]\n",
      " [ 0.01084834  0.03157524  0.05263724 ...  0.00052738 -0.00196231\n",
      "  -0.00465251]\n",
      " ...\n",
      " [ 0.00110022  0.02602449  0.05123494 ...  0.01076978  0.00510537\n",
      "  -0.0007906 ]\n",
      " [-0.00020228  0.02542342  0.05131581 ...  0.01271337  0.00638544\n",
      "  -0.00017697]\n",
      " [-0.00127098  0.0249985   0.05151139 ...  0.01459729  0.00760132\n",
      "   0.00036823]]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(f\"string_data/\" + filename + \".npz\")\n",
    "t = data[\"t\"]\n",
    "t = t[t<=4]\n",
    "x = data[\"X\"]\n",
    "x = x[:t.shape[0]]\n",
    "\n",
    "\n",
    "train = data[\"X_train\"]\n",
    "validation = data[\"X_validation\"]\n",
    "total_input = torch.tensor(data[\"total_X\"],dtype=torch.float32)\n",
    "total_input = total_input[total_input[:,0]<=4]\n",
    "\n",
    "data_array = model.forward(total_input.to(\"cpu\"))[0].detach().cpu().numpy()\n",
    "data_array = data_array.reshape(t.shape[0],x.shape[0])\n",
    "print(data_array[:10])\n",
    "\n",
    "\n",
    "real_wave              = np.array(data[\"wave\"])\n",
    "real_wave              = real_wave[:t.shape[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaa9a20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T09:41:28.359687Z",
     "start_time": "2022-06-15T09:41:28.346623Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "@gif.frame\n",
    "def helper_plot(data_array,real_wave,x,i):\n",
    "    sep  = int(data_array.shape[0]/2)\n",
    "    data = data_array.copy()\n",
    "    fig,ax = plt.subplots(figsize=(15,10))\n",
    "    \n",
    "    if i < sep:\n",
    "        color1 = \"orange\"\n",
    "        color2 = \"red\"\n",
    "        label1 = \"Model prediction\"\n",
    "        label2 = \"Ground truth\"\n",
    "        marker = \"x\"\n",
    "        alpha2 = 0.5\n",
    "        at2    = AnchoredText(f\"Training t<2s\", prop=dict(size=15), frameon=True, loc='upper center')\n",
    "        order  = [0,1]\n",
    "\n",
    "    \n",
    "    if i >= sep:\n",
    "        \n",
    "        color1 = \"orange\"\n",
    "        label1 = \"Model prediction\"\n",
    "        at2    = AnchoredText(f\"Extrapolating t>2s \", prop=dict(size=15), frameon=True, loc='upper center')\n",
    "        alpha2 = 1\n",
    "        color2 = \"blue\"\n",
    "        label2 = \"Ground truth test data\"\n",
    "        marker = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.plot([0],[0],marker=\"x\",color=\"red\",markersize=12,label=\"Ground truth training data\")\n",
    "        plt.plot([1],[0],marker=\"x\",markersize=12,color=\"red\")\n",
    "        order  = [0,2,1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    #TIME elapsing annotation\n",
    "    at = AnchoredText(f\"t={i/100}s\", prop=dict(size=15), frameon=True, loc='upper left')\n",
    "    at.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\n",
    "    ax.add_artist(at)\n",
    "    \n",
    "    at2.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\n",
    "    ax.add_artist(at2)\n",
    "    \n",
    "    #real plots\n",
    "    \n",
    "    plt.plot(x,data[i,:],color=color1,linestyle=\"solid\",lw=4,label = label1)\n",
    "    plt.plot(x,real_wave[i,:],color=color2,linestyle=\"dashed\",lw=3,label=label2,marker=marker,markersize=12,alpha=alpha2)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    #plt.vlines(x=0,color=\"r\",ymin=-3,ymax=3,lw=4,label=\"Fixed points\")\n",
    "    #plt.vlines(x=1,color=\"red\",linestyles=\"dashed\",ymin=-3,ymax=3,lw=2)\n",
    "    \n",
    "    #plot settings\n",
    "    plt.plot(0,0)\n",
    "    plt.xlim(-0.1,1.1)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Displacement\")\n",
    "    \n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order],fontsize=20)\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.grid()\n",
    "    plt.title(f\"Vibrating String with horizontal speed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "962dcbe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T09:42:20.297692Z",
     "start_time": "2022-06-15T09:41:28.811191Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from io import BytesIO as Buffer\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "frames = []\n",
    "for i in range(data_array.shape[0]):\n",
    "    frames.append(helper_plot(data_array,real_wave,x,i))\n",
    "    \n",
    "frames[0].save(\"test.gif\",save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=10,\n",
    "        loop=0,\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45c680",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-13T16:06:21.210Z"
    }
   },
   "source": [
    "##### f = Image.open('test.gif')\n",
    "f.info['duration'] = 50\n",
    "f.save('out.gif', save_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc240066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Temperature2D/Untitled.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
