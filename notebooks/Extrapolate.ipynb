{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d63500-a7a8-40e2-a92e-5ceddf0288e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
      "\u001b[K     |████████████████████████████████| 708 kB 23.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.22.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (5.4.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2022.1.0)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 39.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
      "\u001b[K     |████████████████████████████████| 529 kB 68.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.0.1)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: torch>=1.9.* in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.11.0a0+17540c5)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 63.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.26.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.3.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.43.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.35.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.6.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.19.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 63.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (18.2.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
      "Installing collected packages: frozenlist, async-timeout, aiosignal, aiohttp, torchmetrics, tensorboard, pyDeprecate, pytorch-lightning\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 frozenlist-1.3.1 pyDeprecate-0.3.2 pytorch-lightning-1.7.7 tensorboard-2.10.1 torchmetrics-0.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting comet-ml\n",
      "  Downloading comet_ml-3.31.15-py3-none-any.whl (412 kB)\n",
      "\u001b[K     |████████████████████████████████| 412 kB 22.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.2\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 62.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from comet-ml) (1.16.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (4.4.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.9.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (2.26.0)\n",
      "Collecting sentry-sdk>=1.1.0\n",
      "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 78.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wurlitzer>=1.0.2\n",
      "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
      "Collecting everett[ini]>=1.0.1\n",
      "  Downloading everett-3.0.0-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.57.0)\n",
      "Collecting dulwich!=0.20.33,>=0.20.6\n",
      "  Downloading dulwich-0.20.46-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (499 kB)\n",
      "\u001b[K     |████████████████████████████████| 499 kB 43.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting semantic-version>=2.8.0\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.8/site-packages (from dulwich!=0.20.33,>=0.20.6->comet-ml) (1.26.7)\n",
      "Collecting configobj\n",
      "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (18.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=3.1.0,>=2.6.0->comet-ml) (3.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (2021.10.8)\n",
      "Collecting urllib3>=1.25\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 79.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: configobj\n",
      "  Building wheel for configobj (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34545 sha256=76f04e89c515dc502b809a7ddc1ddf2f6546af0c6de7f29dbda577269ecb32ec\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n6_au6ag/wheels/34/2a/24/a490264ae9041fd48f778ff393526572c80bb498ddecb07ea5\n",
      "Successfully built configobj\n",
      "Installing collected packages: urllib3, everett, configobj, wurlitzer, wrapt, sentry-sdk, semantic-version, dulwich, comet-ml\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "Successfully installed comet-ml-3.31.15 configobj-5.0.6 dulwich-0.20.46 everett-3.0.0 semantic-version-2.10.0 sentry-sdk-1.10.1 urllib3-1.26.12 wrapt-1.14.1 wurlitzer-3.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pytorch-lightning\n",
    "!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29b8a8b-4cec-4121-9b76-54ee1ea056d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of GPUs is: 1\n",
      "GPU number 0 is Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/notebooks\")\n",
    "from pytorch_lightning import LightningModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from base_lightning import Dataset\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "#from neptune.new.types import File\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from sklearn.linear_model import LassoCV,Lasso, LinearRegression\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor,TQDMProgressBar,EarlyStopping\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def gpu_prints():\n",
    "    print(\"The total number of GPUs is:\",torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU number\",i,\"is\",torch.cuda.get_device_name(i))\n",
    "        \n",
    "gpu_prints()\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0824405c-a939-4346-b3b2-de0a1c968bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalActivation(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pi = torch.tensor([math.pi],dtype=torch.float32,device=\"cuda\")\n",
    "    \n",
    "    def forward(self,input): \n",
    "        \n",
    "        sinusoid = torch.sin(2*self.pi*input)\n",
    "        return sinusoid\n",
    "\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden,init=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.init = init\n",
    "        self.network = self.build_network(hidden,sigma=1)\n",
    "        \n",
    "    def forward(self, input_: torch.Tensor):\n",
    "        \n",
    "        input_ = input_.requires_grad_(True)\n",
    "        return self.network(input_),input_\n",
    "\n",
    "    def build_network(self,hidden,sigma):\n",
    "\n",
    "        network= []\n",
    "        first = nn.Linear(2,hidden)\n",
    "        if self.init:\n",
    "            print(\"Initing NN weights and baises\")\n",
    "            nn.init.normal_(first.weight,0,sigma**2)\n",
    "            nn.init.zeros_(first.bias)\n",
    "        network.append(first)\n",
    "        network.append(SinusoidalActivation())\n",
    "        \n",
    "        second = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(second.weight)\n",
    "            torch.nn.init.zeros_(second.bias)\n",
    "        network.append(second)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        third = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(third.weight)\n",
    "            torch.nn.init.zeros_(third.bias)\n",
    "        network.append(third)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        fourth = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(fourth.weight)\n",
    "            torch.nn.init.zeros_(fourth.bias)\n",
    "        network.append(fourth)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        fith = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(fith.weight)\n",
    "            torch.nn.init.zeros_(fith.bias)\n",
    "        network.append(fith)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        sixth = nn.Linear(hidden,1)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(sixth.weight)\n",
    "            torch.nn.init.zeros_(sixth.bias)\n",
    "        network.append(sixth)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        network.pop()\n",
    "        network = nn.Sequential(*network)\n",
    "        \n",
    "        return network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13d7d9c-d58c-41d1-94ac-7c519552856e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularNN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config,init_NN):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data            = np.load(filename)\n",
    "        a = filename.split('/')\n",
    "        self.dir = a[0]\n",
    "        self.filename = a[-1].split('.npz')[0]\n",
    "        \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "\n",
    "\n",
    "        self.X_train         = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "\n",
    "        self.Y_train         = self.total_Y[self.total_X[:,0]<=2]\n",
    "        self.Y_validation    = self.total_Y[self.total_X[:,0]>=2]\n",
    "\n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "\n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "\n",
    "        self.coiso              = None\n",
    "        self.xi                 = None\n",
    "        self.analytical_du2_dx2 = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.network            = custom_NN(n_in=2,n_hidden=6*[60],n_out=1,init=init_NN)\n",
    "        \n",
    "        self.first_coeff  = -(self.c**2-self.v**2)\n",
    "        self.second_coeff = +2*self.v\n",
    "        \n",
    "        print(\"1st coef:\",self.first_coeff)\n",
    "        print(\"2nd coef:\",self.second_coeff)\n",
    "    \n",
    "    def fig2img(self,fig):\n",
    "        \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def forward(self,input_):\n",
    "\n",
    "        return self.network(input_)\n",
    "\n",
    "    def on_train_start(self):\n",
    "\n",
    "        print(\"Device is:\",self.device)\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=\"Real Wave\")\n",
    "        plt.close()\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "\n",
    "        #forward pass\n",
    "        x,target = batch\n",
    "        prediction,coordinates = self.forward(x)\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction,coordinates) # derivatives\n",
    "\n",
    "        #self.xi = self.least_squares_QR(theta,second_time_deriv) #sparse vector computed using least squares\n",
    "        self.xi = self.least_squares_SK(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction-target)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv+term1+term2)**2)#should be scalar as well\n",
    "        total_loss                          = mse_loss + self.k_pde*pde_loss\n",
    "\n",
    "        #for i,j in enumerate(xi):\n",
    "        #   self.log(f\"Coefficient nr{i}\",j,logger=True,on_epoch=True,on_step=False)\n",
    "        \n",
    "        self.log(f\"Coefficient nr1\",-self.xi[0],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Coefficient nr2\",-self.xi[1],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr1\",torch.abs((-self.xi[0]-self.first_coeff)/self.first_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr2\",torch.abs((-self.xi[1]-self.second_coeff)/self.second_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "    \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "\n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "        \n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "        \n",
    "        \n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        #term1 = -(self.c**2-self.v**2)*du2_dx2\n",
    "        #term2 = +2*self.v*du2_dtdx\n",
    "\n",
    "        term1 = du2_dx2\n",
    "        term2 = du2_dtdx\n",
    "        \n",
    "\n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "\n",
    "            return second_time_deriv,theta,term1,term2\n",
    "\n",
    "        else:\n",
    "\n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "\n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def least_squares_SK(self,theta,second_time_deriv):\n",
    "        \n",
    "        x,y = theta.detach().cpu().numpy(), second_time_deriv.detach().cpu().detach()\n",
    "        coefs = LinearRegression().fit(x,y).coef_\n",
    "        return coefs[0]\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-8)\n",
    "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(mode=\"min\",factor=0.5,patience=500,threshold_mode=\"rel\",threshold=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset    = Dataset(data=self.X_train, labels=self.Y_train)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(self.X_train.shape[0]/6),drop_last=True, num_workers=0, shuffle=True)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=int(self.X_validation.shape[0]/6),\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "        \n",
    "        return val_dataloader\n",
    "\n",
    "    def analytical_derivs(self,x,time):\n",
    "\n",
    "        if self.coiso is None:\n",
    "\n",
    "            self.omega = np.zeros(self.coefs.shape[0])\n",
    "            self.k_rev = np.zeros(self.coefs.shape[0])\n",
    "            self.k_fwd = np.zeros(self.coefs.shape[0])\n",
    "            self.phi   = np.zeros(self.coefs.shape[0])\n",
    "            self.coiso = 1\n",
    "\n",
    "            for i in range(self.coefs.shape[0]):\n",
    "\n",
    "                n = i+1\n",
    "                self.omega[i] = n*np.pi*(self.c**2-self.v**2)/self.c\n",
    "                self.k_rev[i] = n*np.pi*(self.c+self.v)/self.c\n",
    "                self.k_fwd[i] = n*np.pi*(self.c-self.v)/self.c\n",
    "                self.phi[i]   = -n*(np.pi*(self.c+self.v)/(2*self.c)-np.pi/2)\n",
    "\n",
    "\n",
    "\n",
    "        du2_dx2  = np.zeros((len(time),len(x)))\n",
    "        du2_dxdt = np.zeros((len(time),len(x)))\n",
    "        du2_dt2  = np.zeros((len(time),len(x)))\n",
    "\n",
    "        for b,t in enumerate(time):\n",
    "\n",
    "            sum1  = 0\n",
    "            sum2  = 0\n",
    "            sum3  = 0\n",
    "\n",
    "            for n in range(self.coefs.shape[0]):\n",
    "\n",
    "                C1     = self.coefs[n] * np.sin(self.k_fwd[n]*x - self.omega[n]*t - self.phi[n])\n",
    "                C2     = self.coefs[n] * np.sin(self.k_rev[n]*x + self.omega[n]*t + self.phi[n])\n",
    "\n",
    "                sum1 += -self.k_fwd[n]**2*C1 - self.k_rev[n]**2*C2\n",
    "                sum2 += +self.k_fwd[n]*self.omega[n]*C1  - self.k_rev[n]*self.omega[n]*C2\n",
    "                sum3 += -self.omega[n]**2*C1 - self.omega[n]**2*C2\n",
    "\n",
    "            du2_dx2[b,:]  = sum1\n",
    "            du2_dxdt[b,:] = sum2\n",
    "            du2_dt2[b,:]  = sum3\n",
    "\n",
    "        #this analytical derivatives should be [T,X]\n",
    "        return du2_dx2,du2_dxdt,du2_dt2\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "\n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Full predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Full predicted wave\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Difference between true wave and predicted wave\")\n",
    "        plt.close()\n",
    "\n",
    "    def anim(self):\n",
    "\n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "\n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "\n",
    "        plt.legend()\n",
    "        anim.save(f\"{self.dir}/predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",writer=PillowWriter(fps=24))\n",
    "        #image = self.fig2img(anim)\n",
    "        #self.logger.experiment.log_image(image,name=f\"Prediction fig at {self.current_epoch}\")\n",
    "        plt.close()\n",
    "        self.logger.experiment.log_image(f\"{self.dir}/predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",name=f\"Prediction gif at {self.current_epoch}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        self.plot()\n",
    "        self.anim()\n",
    "      \n",
    "        \"\"\"with torch.enable_grad():\n",
    "            predictions,coordinates = self.forward(self.X_train.to(self.device))\n",
    "\n",
    "            #analytical derivatives--> stay constant only need to compute 1 time\n",
    "            if self.analytical_du2_dx2 == None:\n",
    "                self.analy_du2_dx2,self.analy_du2_dxdt,self.analy_du2_dt2 = self.analytical_derivs(self.total_x,self.T[self.T<=2])\n",
    "\n",
    "            #auto diff derivatives\n",
    "            NN_du2_dt2,NN_du2_dxdt,NN_du2_dx2          = self.compute_derivatives(predictions,coordinates,derivs=True)\n",
    "\n",
    "        NN_du2_dt2 = NN_du2_dt2.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "        NN_du2_dxdt= NN_du2_dxdt.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "        NN_du2_dx2 = NN_du2_dx2.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "\n",
    "        dif1 = 100 * np.median(np.abs((NN_du2_dt2[self.analy_du2_dt2>1e-5]  - self.analy_du2_dt2[self.analy_du2_dt2>1e-5])/self.analy_du2_dt2[self.analy_du2_dt2>1e-5]))\n",
    "        dif2 = 100 * np.median(np.abs((NN_du2_dx2[self.analy_du2_dx2>1e-5]  - self.analy_du2_dx2[self.analy_du2_dx2>1e-5])/self.analy_du2_dx2[self.analy_du2_dx2>1e-5]))\n",
    "        dif3 = 100 * np.median(np.abs((NN_du2_dxdt[self.analy_du2_dxdt>1e-5] - self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5])/self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5]))\n",
    "\n",
    "        abs_dif1 = np.mean(np.abs(NN_du2_dt2 - self.analy_du2_dt2))\n",
    "        abs_dif2 = np.mean(np.abs(NN_du2_dx2 - self.analy_du2_dx2))\n",
    "        abs_dif3 = np.mean(np.abs(NN_du2_dxdt- self.analy_du2_dxdt))\n",
    "\n",
    "        self.log(\"Absolute Diff1\",abs_dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff1\",dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dt2\",np.mean(np.abs(NN_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dt2\",np.mean(np.abs(self.analy_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "        self.log(\"Absolute Diff2\",abs_dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff2\",dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dx2\",np.mean(np.abs(NN_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dx2\",np.mean(np.abs(self.analy_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "        self.log(\"Absolute Diff3\",abs_dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff3\",dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dxdt\",np.mean(np.abs(NN_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dxdt\",np.mean(np.abs(self.analy_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\"\"\"\n",
    "\n",
    " \n",
    "\n",
    "    def update_plot(self,i,line1,line2):\n",
    "\n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07909923-59c1-4612-b4d1-6187d6e5f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data            = np.load(filename)\n",
    "        a = filename.split('/')\n",
    "        self.dir = a[0]\n",
    "        self.filename = a[-1].split('.npz')[0]\n",
    "        \n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.first_coeff  = -(self.c**2-self.v**2)\n",
    "        self.second_coeff = +2*self.v\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "        \n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "        \n",
    "        self.initial_xi         = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.k_mse              = config[\"k_mse\"]\n",
    "        self.network            = NN(init=False,hidden=50)\n",
    "        \n",
    "        \n",
    "         \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "\n",
    "        \n",
    "        self.X1              = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.Y1              = self.total_Y[self.total_X[:,0]<=2]\n",
    "        self.network.to(\"cuda:0\")\n",
    " \n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "        self.Y_validation    = self.total_Y[self.X_validation.shape[0]:]\n",
    "        \n",
    "        self.X_fixed_points  = self.X_validation[(self.X_validation[:,1]== 0)  |\n",
    "                                                 (self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 (self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                ]\n",
    "        \n",
    "        self.Y_fixed_points  = self.Y_validation[(self.X_validation[:,1]== 0) |\n",
    "                                                 (self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 (self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                 ]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.X_MSE           = self.X_fixed_points\n",
    "        self.Y_MSE           = self.Y_fixed_points\n",
    "        \n",
    "    \n",
    "        print(\"1st coef:\",self.first_coeff)\n",
    "        print(\"2nd coef:\",self.second_coeff)\n",
    "\n",
    "        \n",
    "    def fig2img(self,fig):\n",
    "        \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        return img\n",
    "        \n",
    "    def forward(self,input_):\n",
    "                \n",
    "        return self.network(input_)\n",
    "    \n",
    "    def on_fit_start(self):      \n",
    "        \n",
    "        self.initial_xi = [1,1]\n",
    "        aux1,aux2 = self.forward(self.X1.to(device='cuda:0'))\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(aux1,aux2)\n",
    "        self.initial_xi = self.least_squares_QR(theta,second_time_deriv).detach()\n",
    "        print(self.initial_xi)\n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        image=self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=\"Real Wave\")     \n",
    "        self.anim()\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "        \n",
    "        #forward pass\n",
    "        batch1 = batch[\"mse\"]\n",
    "        batch2 = batch[\"pde\"]\n",
    "\n",
    "        x1,target1 = batch1\n",
    "        x2,target2 = batch2\n",
    "\n",
    "        prediction1,coordinates1 = self.forward(x1)\n",
    "        prediction2,coordinates2 = self.forward(x2)\n",
    "\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction2,coordinates2)\n",
    "        self.xi = self.least_squares_QR(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction1-target1)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv-(term1+term2))**2)#should be scalar as well\n",
    "        total_loss                          = self.k_mse*mse_loss  + self.k_pde*pde_loss\n",
    "\n",
    "\n",
    "        self.log(f\"Coefficient nr1\",self.xi[0],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Coefficient nr2\",self.xi[1],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr1\",torch.abs((self.xi[0]-self.first_coeff)/self.first_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr2\",torch.abs((self.xi[1]-self.second_coeff)/self.second_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "    \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)      \n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "        \n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "\n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "\n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        term1 = self.initial_xi[0]*du2_dx2\n",
    "        term2 = self.initial_xi[1]*du2_dtdx\n",
    "\n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "\n",
    "            return second_time_deriv,theta,term1,term2\n",
    "\n",
    "        else:\n",
    "\n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "\n",
    "        \n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "\n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-8)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset1   = Dataset(data=self.X_MSE, labels=self.Y_MSE)\n",
    "        dataset2   = Dataset(data=self.X_validation,labels = self.Y_validation)\n",
    "\n",
    "        dataloader1 = torch.utils.data.DataLoader(dataset1, batch_size=int(self.X_MSE.shape[0]/4),drop_last=True, shuffle=True,num_workers=0)\n",
    "        dataloader2 = torch.utils.data.DataLoader(dataset2, batch_size=int(self.X_validation.shape[0]/4),drop_last=True,shuffle=True,num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "        return {\"mse\":dataloader1,\"pde\":dataloader2}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=int(self.X_validation.shape[0]/4),\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "\n",
    "        return val_dataloader\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        \n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Full predicted wave\")\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Difference between true wave and predicted wave\")\n",
    "        plt.close()\n",
    "    \n",
    "    def anim(self):\n",
    "        \n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "        \n",
    "        plt.legend()\n",
    "        writergif = animation.PillowWriter(fps=30)\n",
    "\n",
    "        anim.save(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",writer=\"ffmpeg\")\n",
    "        plt.close()\n",
    "        self.logger.experiment.log_image(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",name=f\"Prediction gif at {self.current_epoch}\")\n",
    "    \n",
    "    def update_plot(self,i,line1,line2):\n",
    "        \n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)\n",
    "        \n",
    "        return lines    \n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        self.plot()\n",
    "        self.anim()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e027d9b-08c1-48c0-ad98-c429ace5fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def training(filename,PATH):\n",
    "    \n",
    "    print(filename)\n",
    "    save_name = filename.split(\"/\")[-1]\n",
    "    save_name = save_name.split(\".npz\")[0]\n",
    "    print(save_name)\n",
    "\n",
    "    config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"filename\":filename,\n",
    "        \"k_pde\":1e-4,\n",
    "        \"k_mse\":10,\n",
    "        \"PATH\":PATH\n",
    "    } \n",
    "    \n",
    "    model = PINN(filename=filename,config=config)\n",
    "    model.load_from_checkpoint(filename=filename,config=config,checkpoint_path=config[\"PATH\"])\n",
    "    model.to(\"cuda:0\")\n",
    "    print(model)\n",
    "    \n",
    "\n",
    "    comet_logger = CometLogger(\n",
    "        api_key=\"kZhkiprqabfgQqOTbHNHpOJvf\",\n",
    "        workspace=\"jose-bastos\",\n",
    "        project_name=\"temp_pinn\"  # Optional\n",
    "    )\n",
    "\n",
    "    comet_logger.log_hyperparams(config)\n",
    "    \n",
    "    epochs = 20\n",
    "    epochs = epochs*10**3+1\n",
    "    kwargs = {\"max_epochs\":epochs ,\n",
    "              \"accelerator\": \"gpu\",\n",
    "              \"devices\":1,\n",
    "              \"num_sanity_val_steps\": 0,\n",
    "              \"logger\": comet_logger,\n",
    "              \"check_val_every_n_epoch\":1000,\n",
    "              \"enable_checkpointing\":False,\n",
    "              \"enable_progress_bar\":False\n",
    "             }\n",
    "\n",
    "    trainer = Trainer(**kwargs,resume_from_checkpoint=config[\"PATH\"])\n",
    "    trainer.fit(model)\n",
    "    trainer.save_checkpoint(f\"resolution/models/PINNs/temporal/{save_name}_{epochs}k_.ckpt\")\n",
    "\n",
    "    \n",
    "    comet_logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d9c43-5b4f-4727-9bc7-a78752d4b861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8077bbe5-299f-46ff-8470-ad814f85bf55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.005_dx=0.040.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.002_dx=0.005.npz\"\n",
    "path_ = \"resolution/models/NN/spatial/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.050_15000.ckpt\"\n",
    "training(filename=filename,PATH=path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7010424-8d46-41b5-bf95-147e7684dce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.001_dx=0.005.npz\n",
      "c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.001_dx=0.005\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;66;03m#\"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.005.npz\",\u001b[39;00m\n\u001b[1;32m      7\u001b[0m          \u001b[38;5;66;03m#\"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.020_dx=0.005.npz\",\u001b[39;00m\n\u001b[1;32m      8\u001b[0m          \u001b[38;5;66;03m#\"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\",\u001b[39;00m\n\u001b[1;32m      9\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mString/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.001_dx=0.005.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files)):\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(filename, PATH)\u001b[0m\n\u001b[1;32m     11\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m:filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m:PATH\n\u001b[1;32m     17\u001b[0m } \n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m PINN(filename\u001b[38;5;241m=\u001b[39mfilename,config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPATH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:184\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 184\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     extension \u001b[38;5;241m=\u001b[39m hparams_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:47\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     45\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:920\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 920\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "paths = [#\"String/resolution/models/NN/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.005_15k.ckpt\",\n",
    "         #\"String/resolution/models/NN/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.020_dx=0.005_15k.ckpt\",\n",
    "         #\"String/resolution/models/NN/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005_15kepochs.ckpt\",\n",
    "         \"String/resolution/models/NN/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.001_dx=0.005_15k.ckpt\"]\n",
    "         \n",
    "files = [#\"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.005.npz\",\n",
    "         #\"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.020_dx=0.005.npz\",\n",
    "         #\"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.005.npz\",\n",
    "         \"String/resolution/data/temporal/c=1_v=0.5c_noise=0.0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.001_dx=0.005.npz\"]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    training(filename = files[i],PATH=paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6385ad2-8b96-42af-b999-7c3d15b05ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfbas\n"
     ]
    }
   ],
   "source": [
    "print(\"asdfbas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766aea7-81fc-4238-aa7f-c1f117154bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
