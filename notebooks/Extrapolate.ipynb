{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d63500-a7a8-40e2-a92e-5ceddf0288e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.8/site-packages (1.7.7)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.9.* in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.11.0a0+17540c5)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (1.22.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (4.0.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (5.4.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (0.3.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning) (2.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.0.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.43.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.35.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.19.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (18.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting comet-ml\n",
      "  Downloading comet_ml-3.31.15-py3-none-any.whl (412 kB)\n",
      "\u001b[K     |████████████████████████████████| 412 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentry-sdk>=1.1.0\n",
      "  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 48.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (4.4.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.9.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from comet-ml) (1.16.0)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (0.57.0)\n",
      "Collecting wurlitzer>=1.0.2\n",
      "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
      "Collecting everett[ini]>=1.0.1\n",
      "  Downloading everett-3.0.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting semantic-version>=2.8.0\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.8/site-packages (from comet-ml) (2.26.0)\n",
      "Collecting wrapt>=1.11.2\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 49.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dulwich!=0.20.33,>=0.20.6\n",
      "  Downloading dulwich-0.20.46-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (499 kB)\n",
      "\u001b[K     |████████████████████████████████| 499 kB 54.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.8/site-packages (from dulwich!=0.20.33,>=0.20.6->comet-ml) (1.26.7)\n",
      "Collecting configobj\n",
      "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (18.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.18.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=3.1.0,>=2.6.0->comet-ml) (3.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.18.4->comet-ml) (2.0.9)\n",
      "Collecting urllib3>=1.25\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 31.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: configobj\n",
      "  Building wheel for configobj (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34545 sha256=d3f5db1989aded1da07b612118539263d1e445b780d2de5e3ee990546dd37c95\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_c9m7im6/wheels/34/2a/24/a490264ae9041fd48f778ff393526572c80bb498ddecb07ea5\n",
      "Successfully built configobj\n",
      "\u001b[33mWARNING: Error parsing requirements for urllib3: [Errno 2] No such file or directory: '/opt/conda/lib/python3.8/site-packages/urllib3-1.26.7.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: urllib3, everett, configobj, wurlitzer, wrapt, sentry-sdk, semantic-version, dulwich, comet-ml\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
      "Successfully installed comet-ml-3.31.15 configobj-5.0.6 dulwich-0.20.46 everett-3.0.0 semantic-version-2.10.0 sentry-sdk-1.9.10 urllib3-1.26.12 wrapt-1.14.1 wurlitzer-3.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pytorch-lightning\n",
    "!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29b8a8b-4cec-4121-9b76-54ee1ea056d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of GPUs is: 1\n",
      "GPU number 0 is Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/notebooks\")\n",
    "from pytorch_lightning import LightningModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from base_lightning import Dataset\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "#from neptune.new.types import File\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from sklearn.linear_model import LassoCV,Lasso, LinearRegression\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor,TQDMProgressBar,EarlyStopping\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def gpu_prints():\n",
    "    print(\"The total number of GPUs is:\",torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU number\",i,\"is\",torch.cuda.get_device_name(i))\n",
    "        \n",
    "gpu_prints()\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0824405c-a939-4346-b3b2-de0a1c968bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalActivation(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pi = torch.tensor([math.pi],dtype=torch.float32,device=\"cuda\")\n",
    "    \n",
    "    def forward(self,input): \n",
    "        \n",
    "        sinusoid = torch.sin(2*self.pi*input)\n",
    "        return sinusoid\n",
    "\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden,init=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.init = init\n",
    "        self.network = self.build_network(hidden,sigma=1)\n",
    "        \n",
    "    def forward(self, input_: torch.Tensor):\n",
    "        \n",
    "        input_ = input_.requires_grad_(True)\n",
    "        return self.network(input_),input_\n",
    "\n",
    "    def build_network(self,hidden,sigma):\n",
    "\n",
    "        network= []\n",
    "        first = nn.Linear(2,hidden)\n",
    "        if self.init:\n",
    "            print(\"Initing NN weights and baises\")\n",
    "            nn.init.normal_(first.weight,0,sigma**2)\n",
    "            nn.init.zeros_(first.bias)\n",
    "        network.append(first)\n",
    "        network.append(SinusoidalActivation())\n",
    "        \n",
    "        second = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(second.weight)\n",
    "            torch.nn.init.zeros_(second.bias)\n",
    "        network.append(second)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        third = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(third.weight)\n",
    "            torch.nn.init.zeros_(third.bias)\n",
    "        network.append(third)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        fourth = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(fourth.weight)\n",
    "            torch.nn.init.zeros_(fourth.bias)\n",
    "        network.append(fourth)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        fith = nn.Linear(hidden,hidden)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(fith.weight)\n",
    "            torch.nn.init.zeros_(fith.bias)\n",
    "        network.append(fith)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        sixth = nn.Linear(hidden,1)\n",
    "        if self.init:\n",
    "            torch.nn.init.xavier_uniform_(sixth.weight)\n",
    "            torch.nn.init.zeros_(sixth.bias)\n",
    "        network.append(sixth)\n",
    "        network.append(nn.Tanh())\n",
    "        \n",
    "        network.pop()\n",
    "        network = nn.Sequential(*network)\n",
    "        \n",
    "        return network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13d7d9c-d58c-41d1-94ac-7c519552856e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularNN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config,init_NN):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data            = np.load(filename)\n",
    "        a = filename.split('/')\n",
    "        self.dir = a[0]\n",
    "        self.filename = a[-1].split('.npz')[0]\n",
    "        \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "\n",
    "\n",
    "        self.X_train         = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "\n",
    "        self.Y_train         = self.total_Y[self.total_X[:,0]<=2]\n",
    "        self.Y_validation    = self.total_Y[self.total_X[:,0]>=2]\n",
    "\n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "\n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "\n",
    "        self.coiso              = None\n",
    "        self.xi                 = None\n",
    "        self.analytical_du2_dx2 = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.network            = custom_NN(n_in=2,n_hidden=6*[60],n_out=1,init=init_NN)\n",
    "        \n",
    "        self.first_coeff  = -(self.c**2-self.v**2)\n",
    "        self.second_coeff = +2*self.v\n",
    "        \n",
    "        print(\"1st coef:\",self.first_coeff)\n",
    "        print(\"2nd coef:\",self.second_coeff)\n",
    "    \n",
    "    def fig2img(self,fig):\n",
    "        \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def forward(self,input_):\n",
    "\n",
    "        return self.network(input_)\n",
    "\n",
    "    def on_train_start(self):\n",
    "\n",
    "        print(\"Device is:\",self.device)\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=\"Real Wave\")\n",
    "        plt.close()\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "\n",
    "        #forward pass\n",
    "        x,target = batch\n",
    "        prediction,coordinates = self.forward(x)\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction,coordinates) # derivatives\n",
    "\n",
    "        #self.xi = self.least_squares_QR(theta,second_time_deriv) #sparse vector computed using least squares\n",
    "        self.xi = self.least_squares_SK(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction-target)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv+term1+term2)**2)#should be scalar as well\n",
    "        total_loss                          = mse_loss + self.k_pde*pde_loss\n",
    "\n",
    "        #for i,j in enumerate(xi):\n",
    "        #   self.log(f\"Coefficient nr{i}\",j,logger=True,on_epoch=True,on_step=False)\n",
    "        \n",
    "        self.log(f\"Coefficient nr1\",-self.xi[0],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Coefficient nr2\",-self.xi[1],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr1\",torch.abs((-self.xi[0]-self.first_coeff)/self.first_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr2\",torch.abs((-self.xi[1]-self.second_coeff)/self.second_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "    \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "\n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "        \n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "        \n",
    "        \n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        #term1 = -(self.c**2-self.v**2)*du2_dx2\n",
    "        #term2 = +2*self.v*du2_dtdx\n",
    "\n",
    "        term1 = du2_dx2\n",
    "        term2 = du2_dtdx\n",
    "        \n",
    "\n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "\n",
    "            return second_time_deriv,theta,term1,term2\n",
    "\n",
    "        else:\n",
    "\n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "\n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def least_squares_SK(self,theta,second_time_deriv):\n",
    "        \n",
    "        x,y = theta.detach().cpu().numpy(), second_time_deriv.detach().cpu().detach()\n",
    "        coefs = LinearRegression().fit(x,y).coef_\n",
    "        return coefs[0]\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-8)\n",
    "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(mode=\"min\",factor=0.5,patience=500,threshold_mode=\"rel\",threshold=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset    = Dataset(data=self.X_train, labels=self.Y_train)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(self.X_train.shape[0]/6),drop_last=True, num_workers=0, shuffle=True)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=int(self.X_validation.shape[0]/6),\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "        \n",
    "        return val_dataloader\n",
    "\n",
    "    def analytical_derivs(self,x,time):\n",
    "\n",
    "        if self.coiso is None:\n",
    "\n",
    "            self.omega = np.zeros(self.coefs.shape[0])\n",
    "            self.k_rev = np.zeros(self.coefs.shape[0])\n",
    "            self.k_fwd = np.zeros(self.coefs.shape[0])\n",
    "            self.phi   = np.zeros(self.coefs.shape[0])\n",
    "            self.coiso = 1\n",
    "\n",
    "            for i in range(self.coefs.shape[0]):\n",
    "\n",
    "                n = i+1\n",
    "                self.omega[i] = n*np.pi*(self.c**2-self.v**2)/self.c\n",
    "                self.k_rev[i] = n*np.pi*(self.c+self.v)/self.c\n",
    "                self.k_fwd[i] = n*np.pi*(self.c-self.v)/self.c\n",
    "                self.phi[i]   = -n*(np.pi*(self.c+self.v)/(2*self.c)-np.pi/2)\n",
    "\n",
    "\n",
    "\n",
    "        du2_dx2  = np.zeros((len(time),len(x)))\n",
    "        du2_dxdt = np.zeros((len(time),len(x)))\n",
    "        du2_dt2  = np.zeros((len(time),len(x)))\n",
    "\n",
    "        for b,t in enumerate(time):\n",
    "\n",
    "            sum1  = 0\n",
    "            sum2  = 0\n",
    "            sum3  = 0\n",
    "\n",
    "            for n in range(self.coefs.shape[0]):\n",
    "\n",
    "                C1     = self.coefs[n] * np.sin(self.k_fwd[n]*x - self.omega[n]*t - self.phi[n])\n",
    "                C2     = self.coefs[n] * np.sin(self.k_rev[n]*x + self.omega[n]*t + self.phi[n])\n",
    "\n",
    "                sum1 += -self.k_fwd[n]**2*C1 - self.k_rev[n]**2*C2\n",
    "                sum2 += +self.k_fwd[n]*self.omega[n]*C1  - self.k_rev[n]*self.omega[n]*C2\n",
    "                sum3 += -self.omega[n]**2*C1 - self.omega[n]**2*C2\n",
    "\n",
    "            du2_dx2[b,:]  = sum1\n",
    "            du2_dxdt[b,:] = sum2\n",
    "            du2_dt2[b,:]  = sum3\n",
    "\n",
    "        #this analytical derivatives should be [T,X]\n",
    "        return du2_dx2,du2_dxdt,du2_dt2\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "\n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Full predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Full predicted wave\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Difference between true wave and predicted wave\")\n",
    "        plt.close()\n",
    "\n",
    "    def anim(self):\n",
    "\n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "\n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "\n",
    "        plt.legend()\n",
    "        anim.save(f\"{self.dir}/predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",writer=PillowWriter(fps=24))\n",
    "        #image = self.fig2img(anim)\n",
    "        #self.logger.experiment.log_image(image,name=f\"Prediction fig at {self.current_epoch}\")\n",
    "        plt.close()\n",
    "        self.logger.experiment.log_image(f\"{self.dir}/predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",name=f\"Prediction gif at {self.current_epoch}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        self.plot()\n",
    "        self.anim()\n",
    "      \n",
    "        \"\"\"with torch.enable_grad():\n",
    "            predictions,coordinates = self.forward(self.X_train.to(self.device))\n",
    "\n",
    "            #analytical derivatives--> stay constant only need to compute 1 time\n",
    "            if self.analytical_du2_dx2 == None:\n",
    "                self.analy_du2_dx2,self.analy_du2_dxdt,self.analy_du2_dt2 = self.analytical_derivs(self.total_x,self.T[self.T<=2])\n",
    "\n",
    "            #auto diff derivatives\n",
    "            NN_du2_dt2,NN_du2_dxdt,NN_du2_dx2          = self.compute_derivatives(predictions,coordinates,derivs=True)\n",
    "\n",
    "        NN_du2_dt2 = NN_du2_dt2.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "        NN_du2_dxdt= NN_du2_dxdt.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "        NN_du2_dx2 = NN_du2_dx2.detach().cpu().numpy().reshape(-1,self.total_x.shape[0])\n",
    "\n",
    "        dif1 = 100 * np.median(np.abs((NN_du2_dt2[self.analy_du2_dt2>1e-5]  - self.analy_du2_dt2[self.analy_du2_dt2>1e-5])/self.analy_du2_dt2[self.analy_du2_dt2>1e-5]))\n",
    "        dif2 = 100 * np.median(np.abs((NN_du2_dx2[self.analy_du2_dx2>1e-5]  - self.analy_du2_dx2[self.analy_du2_dx2>1e-5])/self.analy_du2_dx2[self.analy_du2_dx2>1e-5]))\n",
    "        dif3 = 100 * np.median(np.abs((NN_du2_dxdt[self.analy_du2_dxdt>1e-5] - self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5])/self.analy_du2_dxdt[self.analy_du2_dxdt>1e-5]))\n",
    "\n",
    "        abs_dif1 = np.mean(np.abs(NN_du2_dt2 - self.analy_du2_dt2))\n",
    "        abs_dif2 = np.mean(np.abs(NN_du2_dx2 - self.analy_du2_dx2))\n",
    "        abs_dif3 = np.mean(np.abs(NN_du2_dxdt- self.analy_du2_dxdt))\n",
    "\n",
    "        self.log(\"Absolute Diff1\",abs_dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff1\",dif1,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dt2\",np.mean(np.abs(NN_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dt2\",np.mean(np.abs(self.analy_du2_dt2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "        self.log(\"Absolute Diff2\",abs_dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff2\",dif2,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dx2\",np.mean(np.abs(NN_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dx2\",np.mean(np.abs(self.analy_du2_dx2)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "\n",
    "        self.log(\"Absolute Diff3\",abs_dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"Relative Diff3\",dif3,on_step=False,on_epoch=True,prog_bar=False,logger=True)\n",
    "        self.log(\"NN_du2_dxdt\",np.mean(np.abs(NN_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\n",
    "        self.log(\"Analy_du2_dxdt\",np.mean(np.abs(self.analy_du2_dxdt)),on_step=False,on_epoch=True,logger=True,prog_bar=False)\"\"\"\n",
    "\n",
    " \n",
    "\n",
    "    def update_plot(self,i,line1,line2):\n",
    "\n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07909923-59c1-4612-b4d1-6187d6e5f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(LightningModule):\n",
    "\n",
    "    def __init__(self,filename,config):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data            = np.load(filename)\n",
    "        a = filename.split('/')\n",
    "        self.dir = a[0]\n",
    "        self.filename = a[-1].split('.npz')[0]\n",
    "        \n",
    "        self.c               = torch.tensor(self.data[\"c\"],dtype=torch.float32)\n",
    "        self.v               = torch.tensor(self.data[\"v\"],dtype=torch.float32)\n",
    "        self.first_coeff  = -(self.c**2-self.v**2)\n",
    "        self.second_coeff = +2*self.v\n",
    "        self.total_x         = torch.tensor(self.data[\"X\"],dtype=torch.float32)\n",
    "        self.T               = torch.tensor(self.data[\"t\"],dtype=torch.float32)\n",
    "        self.T               = self.T[self.T<=4]\n",
    "        \n",
    "        self.U               = np.array(self.data[\"wave\"])\n",
    "        self.U               = self.U[:self.T.shape[0]]\n",
    "        self.coefs           = self.data[\"coefs\"]\n",
    "\n",
    "        \n",
    "        self.initial_xi         = None\n",
    "        self.lr                 = config[\"lr\"]\n",
    "        self.k_pde              = config[\"k_pde\"]\n",
    "        self.k_mse              = config[\"k_mse\"]\n",
    "        self.network            = NN(init=False,hidden=30)\n",
    "        \n",
    "        \n",
    "         \n",
    "        self.total_X         = torch.tensor(self.data[\"total_X\"],dtype=torch.float32)\n",
    "        self.total_X         = self.total_X[self.total_X[:,0]<=4]\n",
    "        self.total_Y         = torch.tensor(self.data[\"total_Y\"],dtype=torch.float32)\n",
    "        self.total_Y         = self.total_Y[:self.total_X.shape[0]]\n",
    "\n",
    "        \n",
    "        self.X1              = self.total_X[self.total_X[:,0]<=2]\n",
    "        self.Y1              = self.total_Y[self.total_X[:,0]<=2]\n",
    "        self.network.to(\"cuda:0\")\n",
    " \n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        self.X_validation    = self.total_X[self.total_X[:,0]>=2]\n",
    "        self.Y_validation    = self.total_Y[self.X_validation.shape[0]:]\n",
    "        \n",
    "        self.X_fixed_points  = self.X_validation[(self.X_validation[:,1]== 0)  |\n",
    "                                                 (self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 (self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                ]\n",
    "        \n",
    "        self.Y_fixed_points  = self.Y_validation[(self.X_validation[:,1]== 0) |\n",
    "                                                 (self.X_validation[:,1]== 0.1)|\n",
    "                                                 #(self.X_validation[:,1]== 0.2)|\n",
    "                                                 #(self.X_validation[:,1]== 0.3)|\n",
    "                                                 #(self.X_validation[:,1]== 0.4)|\n",
    "                                                 #(self.X_validation[:,1]== 0.5)|\n",
    "                                                 #(self.X_validation[:,1]== 0.6)|\n",
    "                                                 #(self.X_validation[:,1]== 0.7)|\n",
    "                                                 #(self.X_validation[:,1]== 0.8)|\n",
    "                                                 (self.X_validation[:,1]== 0.9)|\n",
    "                                                 (self.X_validation[:,1]== 1)\n",
    "                                                 ]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.X_MSE           = self.X_fixed_points\n",
    "        self.Y_MSE           = self.Y_fixed_points\n",
    "        \n",
    "    \n",
    "        print(\"1st coef:\",self.first_coeff)\n",
    "        print(\"2nd coef:\",self.second_coeff)\n",
    "\n",
    "        \n",
    "    def fig2img(self,fig):\n",
    "        \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        return img\n",
    "        \n",
    "    def forward(self,input_):\n",
    "                \n",
    "        return self.network(input_)\n",
    "    \n",
    "    def on_fit_start(self):      \n",
    "        \n",
    "        self.initial_xi = [1,1]\n",
    "        aux1,aux2 = self.forward(self.X1.to(device='cuda:0'))\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(aux1,aux2)\n",
    "        self.initial_xi = self.least_squares_QR(theta,second_time_deriv).detach()\n",
    "        print(self.initial_xi)\n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(self.U,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Real wave\")\n",
    "        image=self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=\"Real Wave\")     \n",
    "        self.anim()\n",
    "\n",
    "    def training_step(self, batch,batch_idx):\n",
    "        \n",
    "        #forward pass\n",
    "        batch1 = batch[\"mse\"]\n",
    "        batch2 = batch[\"pde\"]\n",
    "\n",
    "        x1,target1 = batch1\n",
    "        x2,target2 = batch2\n",
    "\n",
    "        prediction1,coordinates1 = self.forward(x1)\n",
    "        prediction2,coordinates2 = self.forward(x2)\n",
    "\n",
    "        second_time_deriv,theta,term1,term2 = self.compute_derivatives(prediction2,coordinates2)\n",
    "        self.xi = self.least_squares_QR(theta,second_time_deriv)\n",
    "        \n",
    "        #losses\n",
    "        mse_loss                            = torch.mean((prediction1-target1)**2) # scalar\n",
    "        pde_loss                            = torch.mean((second_time_deriv-(term1+term2))**2)#should be scalar as well\n",
    "        total_loss                          = self.k_mse*mse_loss  + self.k_pde*pde_loss\n",
    "\n",
    "\n",
    "        self.log(f\"Coefficient nr1\",self.xi[0],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Coefficient nr2\",self.xi[1],logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr1\",torch.abs((self.xi[0]-self.first_coeff)/self.first_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "        self.log(f\"Error in coefficient nr2\",torch.abs((self.xi[1]-self.second_coeff)/self.second_coeff)*100,logger=True,on_epoch=True,on_step=False)\n",
    "    \n",
    "        self.log(\"MSE Loss\",mse_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"PDE Loss\",pde_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "        self.log(\"Total Loss\",total_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)      \n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "\n",
    "        x,target = batch\n",
    "        val_prediction,val_coordinates = self.forward(x)\n",
    "        val_loss = torch.mean((val_prediction-target)**2)\n",
    "        self.log(\"Validation Loss\",val_loss,on_step=False,on_epoch=True,logger=True,prog_bar=True)\n",
    "\n",
    "\n",
    "    def compute_derivatives(self,prediction,coords,derivs=False):\n",
    "        \n",
    "        du = grad(outputs=prediction, inputs=coords, grad_outputs=torch.ones_like(prediction), create_graph=True)[0]\n",
    "        first_time_deriv = du[:,0:1]\n",
    "        du_dx            = du[:,1:2]\n",
    "\n",
    "        du2 = grad(outputs=first_time_deriv,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0]\n",
    "        second_time_deriv = du2[:,0:1]\n",
    "        du2_dtdx          = du2[:,1:2]\n",
    "\n",
    "        du2_dx2 = grad(outputs=du_dx,inputs=coords,grad_outputs=torch.ones_like(prediction),create_graph=True)[0][:,1:2]\n",
    "\n",
    "        term1 = self.initial_xi[0]*du2_dx2\n",
    "        term2 = self.initial_xi[1]*du2_dtdx\n",
    "\n",
    "        theta = torch.reshape(torch.cat((term1,term2),dim=1),(prediction.shape[0],-1))\n",
    "\n",
    "        if not derivs:\n",
    "\n",
    "            return second_time_deriv,theta,term1,term2\n",
    "\n",
    "        else:\n",
    "\n",
    "            return second_time_deriv,du2_dtdx,du2_dx2\n",
    "\n",
    "\n",
    "        \n",
    "    def least_squares_QR(self,theta,second_deriv):\n",
    "\n",
    "        Q,R = torch.linalg.qr(theta)\n",
    "        xi  = torch.inverse(R) @ Q.T @ second_deriv\n",
    "        return xi\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),lr=self.lr,amsgrad=True,weight_decay=1e-8)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        dataset1   = Dataset(data=self.X_MSE, labels=self.Y_MSE)\n",
    "        dataset2   = Dataset(data=self.X_validation,labels = self.Y_validation)\n",
    "\n",
    "        dataloader1 = torch.utils.data.DataLoader(dataset1, batch_size=int(self.X_MSE.shape[0]/4),drop_last=True, shuffle=True,num_workers=0)\n",
    "        dataloader2 = torch.utils.data.DataLoader(dataset2, batch_size=int(self.X_validation.shape[0]/4),drop_last=True,shuffle=True,num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "        return {\"mse\":dataloader1,\"pde\":dataloader2}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "\n",
    "        val_dataset = Dataset(data=self.X_validation, labels=self.Y_validation)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=int(self.X_validation.shape[0]/4),\n",
    "                                                     drop_last=True, num_workers=0, shuffle=False)\n",
    "\n",
    "        return val_dataloader\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        \n",
    "        total_output = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy().reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(total_output,origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Full predicted wave\")\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        fig,ax1 = plt.subplots(figsize=(20,7))\n",
    "        extent = np.min(self.total_x.detach().cpu().numpy()), np.max(self.total_x.detach().cpu().numpy()), np.min(self.T.detach().cpu().numpy()), np.max(self.T.detach().cpu().numpy())\n",
    "        im1 = plt.imshow(np.abs(total_output-self.U),origin=\"lower\",cmap=plt.cm.magma,extent=extent,aspect=\"auto\",interpolation=None)\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.title(f\"Difference between true wave and predicted wave at epoch {self.current_epoch}\")\n",
    "        image = self.fig2img(fig)\n",
    "        self.logger.experiment.log_image(image,name=f\"Difference between true wave and predicted wave\")\n",
    "        plt.close()\n",
    "    \n",
    "    def anim(self):\n",
    "        \n",
    "        def init():\n",
    "            for line in lines:\n",
    "                line.set_data([],[])\n",
    "            return lines\n",
    "\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax = plt.axes(xlim=(0,1),ylim=(-3,3))\n",
    "        line, = ax.plot([], [], lw=3)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(-3,3)\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Displacement\")\n",
    "        plt.title(f\"Prediction for epoch {self.current_epoch}\",fontsize=20)\n",
    "        lines = []\n",
    "        lobj1 = ax.plot([],[],lw=3,label=\"Predicted\")[0]\n",
    "        lobj2 = ax.plot([],[],lw=3,label=\"Real\")[0]\n",
    "        lines.append(lobj1)\n",
    "        lines.append(lobj2)\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "        anim = FuncAnimation(fig,\n",
    "                    self.update_plot,\n",
    "                    init_func=init,\n",
    "                    frames=int(len(self.T)),\n",
    "                    fargs=(lines),\n",
    "                     blit=True,\n",
    "                    interval=100,\n",
    "                    repeat=True)\n",
    "        \n",
    "        plt.legend()\n",
    "        writergif = animation.PillowWriter(fps=30)\n",
    "\n",
    "        anim.save(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",writer=\"ffmpeg\")\n",
    "        plt.close()\n",
    "        self.logger.experiment.log_image(f\"predictions/{self.filename}_epoch{self.current_epoch}_{now.minute}{now.second}\" + \".gif\",name=f\"Prediction gif at {self.current_epoch}\")\n",
    "    \n",
    "    def update_plot(self,i,line1,line2):\n",
    "        \n",
    "        a = self.forward(self.total_X.to(self.device))[0].detach().cpu().numpy()\n",
    "        b   = a.reshape(self.T.shape[0],self.total_x.shape[0])\n",
    "        line1.set_data(self.total_x,b[i,:])\n",
    "        line2.set_data(self.total_x,self.U[i,:])\n",
    "        lines = (line1,line2)\n",
    "        \n",
    "        return lines    \n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        self.plot()\n",
    "        self.anim()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e027d9b-08c1-48c0-ad98-c429ace5fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def training(filename,PATH):\n",
    "    \n",
    "    print(filename)\n",
    "    save_name = filename.split(\"/\")[-1]\n",
    "    save_name = save_name.split(\".npz\")[0]\n",
    "\n",
    "    config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"filename\":filename,\n",
    "        \"k_pde\":1e-4,\n",
    "        \"k_mse\":10,\n",
    "        \"PATH\":PATH\n",
    "    } \n",
    "    \n",
    "    model = PINN(filename=filename,config=config)\n",
    "    model.load_from_checkpoint(filename=filename,config=config,checkpoint_path=config[\"PATH\"])\n",
    "    model.to(\"cuda:0\")\n",
    "    print(model)\n",
    "    \n",
    "\n",
    "    comet_logger = CometLogger(\n",
    "        api_key=\"kZhkiprqabfgQqOTbHNHpOJvf\",\n",
    "        workspace=\"jose-bastos\",\n",
    "        project_name=\"temp_pinn\"  # Optional\n",
    "    )\n",
    "\n",
    "    comet_logger.log_hyperparams(config)\n",
    "    \n",
    "    epochs = 20\n",
    "    epochs = epochs*10**3+1\n",
    "    kwargs = {\"max_epochs\":epochs ,\n",
    "              \"accelerator\": \"gpu\",\n",
    "              \"devices\":1,\n",
    "              \"num_sanity_val_steps\": 0,\n",
    "              \"logger\": comet_logger,\n",
    "              \"check_val_every_n_epoch\":1000,\n",
    "              \"enable_checkpointing\":False,\n",
    "              \"enable_progress_bar\":False\n",
    "             }\n",
    "\n",
    "    trainer = Trainer(**kwargs,resume_from_checkpoint=config[\"PATH\"])\n",
    "    trainer.fit(model)\n",
    "    trainer.save_checkpoint(f\"resolution/models/PINNs/temporal/{save_name}_{epochs}k_.ckpt\")\n",
    "\n",
    "    \n",
    "    comet_logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d9c43-5b4f-4727-9bc7-a78752d4b861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8077bbe5-299f-46ff-8470-ad814f85bf55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.005_dx=0.040.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=50, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.005_dx=0.040.npz\"\n",
    "path_ = \"resolution/models/NN/spatial/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.050_15000.ckpt\"\n",
    "training(filename=filename,PATH=path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7010424-8d46-41b5-bf95-147e7684dce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040.npz\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "1st coef: tensor(-0.7500)\n",
      "2nd coef: tensor(1.)\n",
      "PINN(\n",
      "  (network): NN(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=30, bias=True)\n",
      "      (1): SinusoidalActivation()\n",
      "      (2): Linear(in_features=30, out_features=30, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=30, out_features=30, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=30, out_features=30, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=30, out_features=30, bias=True)\n",
      "      (9): Tanh()\n",
      "      (10): Linear(in_features=30, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/jose-bastos/temp-pinn/82b31efc9a404b6092d0cff623e48cd1\n",
      "\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:52: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:731: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  ckpt_path = ckpt_path or self.resume_from_checkpoint\n",
      "Restoring states from the checkpoint path at resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040_15k.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type | Params\n",
      "---------------------------------\n",
      "0 | network | NN   | 3.8 K \n",
      "---------------------------------\n",
      "3.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 K     Total params\n",
      "0.015     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6846],\n",
      "        [-0.8782]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "Restored all states from the checkpoint file at resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040_15k.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:98: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 10. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "COMET WARNING: Error exporting current conda environment\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/jose-bastos/temp-pinn/82b31efc9a404b6092d0cff623e48cd1\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     Coefficient nr1 [4206]          : (-0.2225249707698822, 0.5032721757888794)\n",
      "COMET INFO:     Coefficient nr2 [4206]          : (-1.1225836277008057, 0.16750292479991913)\n",
      "COMET INFO:     Error in coefficient nr1 [4206] : (70.33000183105469, 167.1029510498047)\n",
      "COMET INFO:     Error in coefficient nr2 [4206] : (83.24971008300781, 212.2583465576172)\n",
      "COMET INFO:     MSE Loss [4206]                 : (4.467323833523551e-06, 2.281163454055786)\n",
      "COMET INFO:     PDE Loss [4206]                 : (2.3871235847473145, 4944.46240234375)\n",
      "COMET INFO:     Total Loss [4206]               : (0.0002835140621755272, 23.306079864501953)\n",
      "COMET INFO:     Validation Loss [4]             : (1.1756112575531006, 1.177286148071289)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     PATH     : resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040_15k.ckpt\n",
      "COMET INFO:     filename : resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040.npz\n",
      "COMET INFO:     k_mse    : 10\n",
      "COMET INFO:     k_pde    : 0.0001\n",
      "COMET INFO:     lr       : 0.001\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (17.92 MB)\n",
      "COMET INFO:     images                   : 14\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = [\"resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040_15k.ckpt\",\n",
    "         \"resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.020_dx=0.040_15k.ckpt\",\n",
    "         \"resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.040_15k.ckpt\",\n",
    "         \"resolution/models/NN/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.005_dx=0.040_15k.ckpt\"]\n",
    "         \n",
    "files = [\"resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.100_dx=0.040.npz\",\n",
    "         \"resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.020_dx=0.040.npz\",\n",
    "         \"resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.010_dx=0.040.npz\",\n",
    "         \"resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.005_dx=0.040.npz\",\n",
    "         \"resolution/data/temporal2/c=1_v=0.5c_noise=0_modes=0.08_0.49_0.85_0.35_0.15_dt=0.001_dx=0.040.npz\"]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    training(filename = files[i],PATH=paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6385ad2-8b96-42af-b999-7c3d15b05ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
